{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aashmore/CV/blob/main/Anthony/Equivariant%20layers%203%2B1d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VDU28mxgDLW"
      },
      "source": [
        "## Installing NetKet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BESNee4egHXd"
      },
      "source": [
        "On Google Colab, use the following command to install the required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zN-iIXRbx229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "0d4a10f1-ee3b-482d-e0c5-774a0f31b566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Collecting pyparsing<3.1,>=2.3.1 (from matplotlib)\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Installing collected packages: pyparsing, matplotlib\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.0\n",
            "    Uninstalling pyparsing-3.1.0:\n",
            "      Successfully uninstalled pyparsing-3.1.0\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "Successfully installed matplotlib-3.7.2 pyparsing-3.0.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install --upgrade matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_releases.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMQnQodbAruZ",
        "outputId": "2b9811d0-cc8b-4da0-bd95-46e7a295c276"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_releases.html\n",
            "Requirement already satisfied: jax[cuda] in /usr/local/lib/python3.10/dist-packages (0.4.13)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax[cuda]) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from jax[cuda]) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax[cuda]) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax[cuda]) (1.10.1)\n",
            "Requirement already satisfied: jaxlib==0.4.13+cuda11.cudnn86 in /usr/local/lib/python3.10/dist-packages (from jax[cuda]) (0.4.13+cuda11.cudnn86)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLSqb2vjgMpf"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade netket"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9jkt3aMgdsJ"
      },
      "source": [
        "We also want to make sure that Jax is running on the CPU. It benefits from a GPU only for large numbers of spins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxNsXoFHgOX8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAX_PLATFORM_NAME\"] = \"gpu\"\n",
        "%env XLA_PYTHON_CLIENT_PREALLOCATE=false"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "BR5O6rDqCvtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up cloud TPU\n",
        "# import jax.tools.colab_tpu\n",
        "# jax.tools.colab_tpu.setup_tpu()\n",
        "\n",
        "import jax\n",
        "from jax.lib import xla_bridge\n",
        "print(xla_bridge.get_backend().platform)\n",
        "print(jax.devices())"
      ],
      "metadata": {
        "id": "6R8W9NvQXv61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnfP_psBgkB_"
      },
      "source": [
        "Check the install was successful and print the version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq6MigCNgcby",
        "outputId": "0b4804d1-b0c9-445b-a4ee-4ba3d7db0a55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NetKet version: 3.8\n"
          ]
        }
      ],
      "source": [
        "import netket as nk\n",
        "print(f\"NetKet version: {nk.__version__}\")\n",
        "\n",
        "import functools\n",
        "from netket.operator.spin import sigmax, sigmaz\n",
        "import flax.linen as nn\n",
        "import jax.numpy as jnp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFbcr1FajVHb"
      },
      "source": [
        "## Defining the Hamiltonian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8olAjaag_Xm"
      },
      "source": [
        "Start by defining the Hamiltonian of the system. We first define the degrees of freedom we are dealing with by specifying the Hilbert space of the problem. We start with an example of $N\\times N$ spins on a lattice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqexYj-lgmyq",
        "outputId": "e3107e88-4f8a-4793-a1d3-65c086a1e58f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of edges in graph: 1500\n",
            "Number of nodes in graph: 375\n",
            "List of edges in graph: [(212, 297), (84, 148), (0, 5), (40, 41), (270, 274), (343, 344), (321, 325), (73, 74), (33, 38), (303, 307), (150, 214), (354, 358), (66, 71), (106, 107), (317, 327), (336, 340), (7, 21), (47, 57), (51, 356), (99, 104), (366, 368), (369, 373), (40, 54), (343, 357), (230, 300), (165, 170), (263, 333), (106, 120), (32, 91), (198, 203), (296, 366), (207, 208), (65, 124), (240, 241), (172, 186), (98, 157), (3, 5), (20, 94), (273, 274), (31, 332), (131, 190), (36, 38), (247, 258), (53, 127), (306, 307), (64, 365), (24, 329), (164, 223), (69, 71), (280, 291), (86, 160), (339, 340), (372, 374), (197, 256), (10, 21), (102, 104), (19, 335), (313, 324), (119, 193), (43, 54), (135, 137), (52, 368), (346, 357), (152, 226), (76, 87), (168, 170), (180, 181), (185, 259), (38, 97), (301, 327), (213, 214), (218, 292), (71, 130), (31, 57), (42, 332), (230, 303), (246, 247), (104, 163), (263, 336), (9, 11), (80, 214), (279, 280), (137, 196), (296, 369), (42, 44), (26, 99), (59, 133), (312, 313), (159, 220), (164, 298), (170, 229), (10, 11), (27, 329), (313, 314), (92, 166), (345, 346), (63, 368), (203, 262), (43, 44), (16, 27), (60, 362), (346, 347), (125, 199), (225, 286), (236, 295), (76, 77), (49, 60), (158, 232), (269, 328), (82, 93), (301, 317), (191, 265), (31, 47), (115, 126), (334, 350), (200, 270), (224, 298), (135, 140), (233, 303), (186, 191), (97, 113), (168, 173), (266, 336), (219, 224), (0, 302), (299, 369), (16, 17), (33, 335), (193, 207), (1, 302), (9, 14), (49, 50), (66, 368), (330, 334), (82, 83), (287, 372), (60, 64), (159, 223), (39, 41), (4, 20), (363, 367), (75, 80), (115, 116), (34, 48), (93, 97), (72, 74), (37, 53), (16, 30), (108, 113), (126, 130), (225, 289), (22, 338), (49, 63), (100, 114), (55, 371), (61, 302), (82, 96), (309, 373), (133, 147), (115, 129), (166, 180), (35, 105), (0, 4), (7, 308), (68, 138), (12, 14), (0, 305), (40, 341), (101, 171), (45, 47), (62, 136), (73, 374), (33, 338), (162, 223), (173, 232), (366, 367), (78, 80), (95, 169), (348, 349), (66, 371), (206, 265), (19, 30), (111, 113), (28, 344), (257, 316), (128, 202), (228, 289), (239, 298), (52, 63), (144, 146), (290, 349), (355, 366), (103, 114), (8, 142), (161, 235), (85, 96), (212, 286), (177, 179), (194, 268), (118, 129), (210, 212), (227, 301), (151, 162), (243, 245), (255, 256), (260, 334), (113, 172), (20, 93), (2, 75), (288, 289), (293, 367), (146, 205), (106, 132), (53, 126), (18, 19), (3, 305), (35, 108), (179, 238), (86, 159), (36, 338), (68, 141), (25, 36), (119, 192), (69, 371), (101, 174), (103, 104), (134, 208), (234, 295), (239, 373), (85, 86), (136, 137), (96, 101), (7, 23), (347, 357), (366, 370), (118, 119), (58, 74), (77, 87), (129, 134), (169, 170), (300, 361), (40, 56), (151, 152), (91, 107), (202, 203), (103, 117), (195, 200), (235, 236), (106, 122), (228, 233), (5, 75), (9, 311), (169, 183), (261, 266), (172, 188), (25, 26), (42, 344), (3, 7), (202, 216), (294, 299), (17, 27), (36, 40), (235, 249), (69, 73), (268, 282), (360, 365), (135, 139), (31, 347), (109, 123), (168, 172), (201, 206), (234, 239), (11, 81), (231, 233), (175, 189), (44, 114), (264, 266), (9, 13), (276, 277), (34, 335), (208, 222), (16, 317), (6, 7), (309, 310), (67, 368), (21, 23), (241, 255), (167, 226), (49, 350), (39, 40), (75, 79), (342, 343), (54, 56), (274, 288), (200, 259), (13, 24), (72, 73), (105, 107), (108, 112), (87, 89), (307, 321), (4, 320), (233, 292), (46, 57), (138, 140), (122, 195), (155, 229), (120, 122), (340, 354), (37, 353), (266, 325), (79, 90), (237, 298), (188, 262), (153, 155), (299, 358), (112, 123), (94, 105), (221, 295), (303, 364), (16, 42), (127, 138), (254, 328), (178, 189), (83, 217), (236, 310), (160, 171), (287, 361), (12, 13), (211, 222), (269, 343), (29, 102), (13, 14), (45, 46), (231, 236), (244, 255), (62, 135), (193, 209), (46, 47), (78, 79), (264, 269), (95, 168), (45, 347), (79, 80), (128, 201), (272, 331), (112, 113), (161, 234), (34, 50), (305, 364), (145, 146), (105, 110), (194, 267), (138, 143), (178, 179), (227, 300), (100, 116), (211, 212), (171, 176), (260, 333), (133, 149), (112, 126), (152, 162), (204, 209), (244, 245), (115, 131), (293, 366), (166, 182), (277, 278), (199, 215), (178, 192), (65, 135), (310, 311), (270, 275), (232, 248), (98, 168), (303, 308), (80, 150), (45, 49), (265, 281), (244, 258), (131, 201), (2, 87), (336, 341), (96, 100), (78, 82), (277, 291), (164, 234), (369, 374), (92, 102), (111, 115), (310, 324), (184, 185), (141, 143), (58, 374), (144, 148), (174, 176), (302, 361), (207, 209), (210, 214), (240, 242), (184, 198), (243, 247), (257, 331), (181, 192), (273, 275), (290, 364), (15, 16), (306, 308), (318, 319), (250, 264), (156, 220), (176, 235), (48, 49), (339, 341), (65, 138), (351, 352), (209, 268), (81, 82), (98, 171), (242, 301), (114, 115), (131, 204), (275, 334), (88, 99), (147, 148), (180, 182), (5, 64), (164, 237), (308, 367), (121, 132), (213, 215), (197, 270), (230, 304), (181, 182), (154, 165), (246, 248), (263, 337), (103, 119), (214, 215), (187, 198), (279, 281), (296, 370), (21, 22), (26, 100), (312, 314), (38, 111), (169, 185), (54, 55), (253, 264), (158, 292), (30, 335), (71, 144), (202, 218), (87, 88), (286, 297), (104, 177), (235, 251), (88, 89), (120, 121), (319, 330), (137, 210), (268, 284), (241, 267), (121, 122), (153, 154), (352, 363), (11, 70), (170, 243), (154, 155), (44, 103), (203, 276), (187, 188), (236, 309), (109, 125), (122, 207), (220, 221), (180, 185), (269, 342), (8, 78), (213, 218), (253, 254), (212, 222), (231, 235), (175, 191), (41, 111), (286, 287), (246, 251), (264, 268), (208, 224), (13, 314), (74, 144), (227, 237), (319, 320), (279, 284), (238, 252), (330, 335), (241, 257), (46, 347), (352, 353), (271, 285), (274, 290), (1, 15), (140, 210), (345, 350), (12, 61), (105, 109), (304, 318), (62, 147), (307, 323), (173, 243), (138, 142), (117, 119), (337, 351), (34, 350), (120, 124), (340, 356), (319, 333), (206, 276), (171, 175), (150, 152), (153, 157), (0, 64), (352, 366), (239, 309), (204, 208), (183, 185), (216, 218), (249, 251), (227, 312), (190, 201), (282, 284), (113, 183), (24, 25), (315, 317), (146, 216), (57, 58), (256, 267), (348, 350), (179, 249), (90, 91), (141, 142), (251, 310), (123, 124), (174, 175), (284, 343), (156, 157), (3, 64), (14, 73), (130, 141), (189, 190), (47, 106), (163, 174), (257, 330), (222, 223), (255, 257), (80, 139), (239, 312), (272, 346), (196, 207), (2, 76), (290, 363), (288, 290), (18, 20), (229, 240), (35, 109), (63, 64), (262, 273), (68, 142), (101, 175), (113, 186), (373, 374), (244, 260), (146, 219), (32, 117), (366, 371), (277, 293), (130, 131), (143, 213), (9, 70), (14, 148), (328, 344), (179, 252), (310, 326), (163, 164), (141, 145), (196, 197), (75, 136), (174, 178), (247, 248), (229, 230), (280, 281), (262, 263), (240, 244), (184, 200), (197, 282), (50, 120), (295, 296), (3, 8), (273, 277), (83, 153), (36, 41), (287, 297), (247, 261), (306, 310), (18, 23), (250, 266), (116, 186), (69, 74), (280, 294), (339, 343), (10, 24), (149, 219), (313, 327), (43, 57), (346, 360), (76, 90), (215, 285), (87, 136), (180, 184), (137, 222), (9, 73), (248, 318), (213, 217), (281, 351), (246, 250), (75, 139), (276, 278), (72, 362), (279, 283), (258, 260), (6, 8), (237, 286), (309, 311), (291, 293), (342, 344), (345, 349), (324, 326), (84, 85), (283, 294), (60, 365), (357, 359), (117, 118), (316, 327), (122, 196), (150, 151), (349, 360), (8, 67), (167, 240), (271, 297), (183, 184), (41, 100), (1, 27), (12, 302), (200, 273), (165, 166), (12, 73), (23, 82), (216, 217), (74, 133), (233, 306), (198, 199), (56, 115), (249, 250), (107, 166), (266, 339), (78, 139), (89, 148), (29, 103), (282, 283), (140, 199), (205, 216), (299, 372), (11, 85), (283, 284), (315, 316), (44, 118), (316, 317), (276, 281), (6, 11), (238, 254), (257, 267), (309, 314), (322, 333), (349, 350), (39, 44), (271, 287), (1, 17), (304, 320), (337, 353), (272, 345), (89, 223), (183, 187), (216, 220), (19, 20), (249, 253), (322, 323), (18, 320), (52, 53), (257, 342), (355, 356), (45, 50), (315, 319), (125, 195), (78, 83), (176, 246), (348, 352), (19, 33), (158, 228), (111, 116), (343, 359), (362, 372), (322, 336), (209, 279), (228, 292), (52, 66), (191, 261), (144, 149), (355, 369), (64, 305), (85, 99), (224, 294), (275, 345), (186, 187), (118, 132), (210, 215), (219, 220), (151, 165), (77, 136), (243, 248), (255, 259), (252, 253), (10, 311), (110, 169), (288, 292), (15, 17), (18, 22), (32, 106), (285, 286), (3, 308), (43, 344), (318, 320), (226, 237), (143, 202), (48, 50), (259, 270), (65, 139), (30, 32), (36, 341), (351, 353), (81, 83), (312, 361), (25, 39), (98, 172), (69, 374), (22, 33), (234, 298), (114, 116), (325, 336), (131, 205), (231, 292), (55, 66), (147, 149), (70, 311), (159, 160), (358, 369), (164, 238), (17, 76), (176, 249), (300, 364), (192, 193), (197, 271), (50, 109), (209, 282), (225, 226), (77, 211), (83, 142), (242, 315), (346, 372), (226, 227), (258, 259), (116, 175), (76, 102), (275, 348), (87, 148), (5, 78), (259, 260), (38, 112), (291, 292), (9, 314), (149, 208), (6, 308), (292, 293), (71, 145), (324, 325), (182, 241), (22, 23), (153, 214), (39, 341), (325, 326), (104, 178), (357, 358), (215, 274), (55, 56), (28, 39), (72, 374), (247, 263), (358, 359), (137, 211), (248, 307), (48, 53), (61, 72), (280, 296), (170, 244), (10, 26), (281, 340), (81, 86), (313, 329), (332, 342), (203, 277), (43, 59), (314, 373), (114, 119), (346, 362), (76, 92), (245, 315), (167, 252), (11, 84), (278, 348), (12, 314), (44, 117), (28, 29), (276, 280), (6, 10), (309, 313), (61, 62), (21, 26), (272, 282), (39, 43), (2, 12), (54, 59), (94, 95), (13, 27), (51, 53), (16, 32), (127, 128), (354, 356), (46, 60), (1, 317), (49, 65), (28, 42), (120, 125), (160, 161), (79, 93), (82, 98), (153, 158), (251, 321), (73, 314), (94, 108), (284, 354), (303, 367), (127, 141), (14, 84), (160, 174), (57, 347), (8, 82), (261, 262), (19, 320), (119, 178), (272, 357), (24, 26), (41, 115), (294, 295), (52, 353), (152, 211), (57, 59), (74, 148), (327, 328), (45, 350), (185, 244), (90, 92), (7, 323), (301, 312), (107, 181), (360, 361), (218, 277), (31, 42), (123, 125), (40, 356), (334, 345), (140, 214), (156, 158), (173, 247), (97, 108), (189, 191), (201, 202), (206, 280), (306, 367), (59, 118), (222, 224), (234, 235), (239, 313), (86, 220), (92, 151), (267, 268), (25, 326), (125, 184), (32, 105), (14, 87), (300, 301), (152, 286), (158, 217), (30, 31), (15, 317), (63, 65), (47, 120), (333, 334), (191, 250), (151, 177), (31, 32), (4, 15), (48, 350), (80, 153), (113, 187), (224, 283), (64, 65), (37, 48), (146, 220), (97, 98), (148, 149), (179, 253), (19, 35), (322, 338), (141, 146), (312, 373), (52, 68), (355, 371), (122, 132), (221, 291), (174, 179), (85, 101), (254, 324), (118, 134), (189, 194), (240, 245), (151, 167), (4, 5), (21, 323), (181, 195), (273, 278), (37, 38), (54, 356), (242, 327), (15, 19), (306, 311), (318, 322), (22, 323), (70, 71), (48, 52), (339, 344), (351, 355), (55, 356), (63, 68), (62, 72), (81, 85), (25, 41), (114, 118), (10, 326), (67, 308), (88, 102), (126, 128), (43, 359), (121, 135), (154, 168), (23, 93), (187, 201), (56, 126), (21, 25), (0, 2), (28, 329), (89, 159), (54, 58), (321, 322), (33, 35), (253, 267), (61, 362), (51, 52), (150, 211), (84, 86), (354, 355), (66, 68), (212, 271), (54, 359), (99, 101), (16, 332), (245, 304), (58, 69), (40, 51), (167, 241), (132, 134), (49, 365), (278, 337), (149, 223), (91, 102), (260, 319), (200, 274), (165, 167), (311, 370), (124, 135), (182, 256), (293, 352), (106, 117), (233, 307), (198, 200), (46, 72), (215, 289), (157, 168), (266, 340), (248, 322), (8, 81), (172, 183), (299, 373), (281, 355), (134, 193), (41, 114), (161, 295), (74, 147), (24, 326), (56, 129), (58, 59), (107, 180), (57, 359), (89, 162), (91, 92), (227, 361), (140, 213), (13, 29), (32, 42), (51, 55), (84, 89), (124, 125), (173, 246), (46, 62), (157, 158), (28, 44), (139, 140), (206, 279), (79, 95), (58, 72), (150, 155), (190, 191), (172, 173), (112, 128), (91, 105), (223, 224), (183, 188), (94, 110), (124, 138), (216, 221), (256, 257), (127, 143), (178, 194), (157, 171), (197, 207), (289, 290), (249, 254), (160, 176), (26, 96), (190, 204), (63, 365), (24, 28), (110, 180), (315, 320), (256, 270), (348, 353), (90, 94), (47, 132), (123, 127), (137, 147), (156, 160), (3, 67), (186, 188), (130, 144), (189, 193), (219, 221), (163, 177), (255, 260), (252, 254), (196, 210), (288, 293), (4, 305), (193, 204), (285, 287), (297, 298), (229, 243), (155, 214), (37, 338), (27, 28), (63, 67), (330, 331), (262, 276), (188, 247), (70, 371), (60, 61), (77, 150), (363, 364), (75, 77), (221, 280), (181, 207), (34, 45), (93, 94), (110, 183), (108, 110), (25, 341), (254, 313), (126, 127), (159, 161), (143, 216), (176, 250), (287, 346), (100, 111), (6, 67), (192, 194), (209, 283), (309, 370), (133, 144), (225, 227), (242, 316), (193, 194), (166, 177), (275, 349), (0, 1), (199, 210), (5, 79), (17, 90), (155, 289), (121, 147), (33, 34), (232, 243), (50, 123), (181, 197), (34, 35), (66, 67), (265, 276), (83, 156), (67, 68), (99, 100), (285, 290), (116, 189), (100, 101), (132, 133), (331, 342), (236, 370), (149, 222), (133, 134), (182, 255), (166, 167), (215, 288), (88, 104), (107, 117), (159, 164), (199, 200), (248, 321), (121, 137), (6, 70), (232, 233), (281, 354), (154, 170), (20, 90), (225, 230), (265, 266), (187, 203), (53, 123), (298, 299), (258, 263), (199, 213), (86, 156), (331, 332), (291, 296), (33, 37), (253, 269), (58, 359), (119, 189), (232, 246), (364, 365), (324, 329), (84, 88), (283, 297), (66, 70), (265, 279), (96, 98), (316, 330), (13, 329), (99, 103), (319, 335), (185, 255), (150, 154), (129, 131), (349, 363), (46, 362), (107, 192), (352, 368), (331, 345), (218, 288), (205, 206), (162, 164), (165, 169), (195, 197), (198, 202), (136, 147), (228, 230), (59, 129), (78, 142), (245, 319), (169, 180), (261, 263), (205, 219), (278, 352), (91, 117), (3, 4), (202, 213), (294, 296), (36, 37), (235, 246), (327, 329), (69, 70), (268, 279), (360, 362), (372, 373), (230, 289), (102, 103), (263, 322), (135, 136), (152, 225), (296, 355), (256, 282), (109, 120), (168, 169), (201, 203), (26, 85), (185, 258), (234, 236), (218, 291), (251, 325), (175, 186), (81, 142), (267, 269), (284, 358), (124, 140), (9, 10), (208, 219), (14, 88), (300, 302), (157, 173), (42, 43), (268, 269), (241, 252), (47, 121), (18, 323), (333, 335), (59, 132), (190, 206), (75, 76), (274, 285), (80, 154), (92, 165), (230, 364), (196, 222), (108, 109), (307, 318), (125, 198), (256, 272), (109, 110), (340, 351), (158, 231), (142, 143), (191, 264), (77, 162), (175, 176), (224, 297), (208, 209), (167, 177), (186, 190), (130, 146), (241, 242), (219, 223), (163, 179), (182, 192), (29, 99), (274, 275), (196, 212), (81, 145), (307, 308), (15, 20), (226, 240), (285, 289), (318, 323), (229, 245), (95, 165), (300, 305), (340, 341), (259, 273), (30, 35), (17, 102), (351, 356), (262, 278), (128, 198), (333, 338), (22, 36), (161, 231), (325, 339), (231, 295), (55, 69), (194, 264), (159, 163), (358, 372), (171, 173), (260, 330), (225, 229), (204, 206), (182, 267), (293, 363), (258, 262), (237, 239), (291, 295), (270, 272), (6, 311), (321, 323), (324, 328), (303, 305), (134, 204), (153, 217), (39, 344), (336, 338), (96, 97), (166, 192), (277, 288), (369, 371), (129, 130), (328, 339), (233, 367), (111, 112), (310, 321), (162, 163), (361, 372), (20, 79), (144, 145), (2, 61), (195, 196), (53, 112), (212, 285), (177, 178), (35, 94), (316, 342), (228, 229), (86, 145), (245, 318), (210, 211), (68, 127), (331, 357), (184, 195), (278, 351), (243, 244), (101, 160), (23, 97), (250, 261), (56, 130), (156, 217), (328, 329), (89, 163), (361, 362), (321, 326), (51, 56), (134, 207), (283, 299), (302, 312), (354, 359), (2, 136), (316, 332), (129, 133), (349, 365), (328, 342), (331, 347), (251, 324), (217, 218), (284, 357), (195, 199), (152, 237), (250, 251), (228, 232), (301, 302), (38, 108), (242, 252), (261, 265), (334, 335), (30, 332), (205, 221), (71, 141), (24, 29), (294, 298), (367, 368), (104, 174), (155, 225), (90, 95), (301, 315), (188, 258), (360, 364), (31, 45), (170, 240), (123, 128), (334, 348), (92, 177), (203, 273), (156, 161), (97, 111), (236, 306), (201, 205), (306, 370), (269, 339), (27, 317), (234, 238), (231, 232), (264, 265), (297, 299), (122, 181), (300, 304), (27, 29), (30, 34), (238, 249), (15, 320), (330, 332), (333, 337), (60, 62), (4, 18), (271, 282), (77, 151), (48, 353), (363, 365), (1, 12), (345, 347), (93, 95), (105, 106), (37, 51), (304, 315), (110, 184), (226, 252), (138, 139), (337, 348), (143, 217), (155, 228), (171, 172), (29, 88), (188, 261), (0, 61), (5, 139), (204, 205), (62, 121), (221, 294), (237, 238), (84, 145), (95, 154), (254, 327), (238, 239), (17, 91), (270, 271), (128, 187), (287, 360), (271, 272), (50, 124), (303, 304), (21, 326), (161, 220), (1, 2), (304, 305), (83, 157), (336, 337), (194, 253), (7, 18), (51, 353), (226, 242), (337, 338), (116, 190), (369, 370), (227, 286), (259, 275), (370, 371), (343, 354), (60, 65), (363, 368), (22, 38), (93, 98), (11, 145), (325, 341), (55, 71), (126, 131), (358, 374), (23, 96), (290, 360), (162, 211), (7, 8)]\n"
          ]
        }
      ],
      "source": [
        "# size of lattice\n",
        "nx = 3\n",
        "ny = 3\n",
        "nz = 3\n",
        "\n",
        "graph = nk.graph.Lattice(basis_vectors=[[0,0,1],[0,1,0],[1,0,0]],\n",
        "                         site_offsets = [[1/2,0,0],[0,1/2,0],[0,0,1/2]],\n",
        "                         extent = [nz,ny,nx],\n",
        "                         pbc=True\n",
        "                        )\n",
        "\n",
        "# graph = nk.graph.Hypercube(length=L, n_dim=2, pbc=True)\n",
        "\n",
        "print(\"Number of edges in graph:\",graph.n_edges)\n",
        "print(\"Number of nodes in graph:\",graph.n_nodes)\n",
        "\n",
        "print(\"List of edges in graph:\",graph.edges())\n",
        "\n",
        "# graph.draw()\n",
        "\n",
        "# number of nodes in graph\n",
        "N = graph.n_nodes\n",
        "\n",
        "# ZN def\n",
        "ZN = 3\n",
        "num_spin = (ZN - 1) / 2\n",
        "\n",
        "hi = nk.hilbert.Spin(s=num_spin)**(N)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list of positions of the sites / nodes\n",
        "pos_sites = [[0.+i,0.+j,0.+k] for k in range (0,nz) for j in range (0,ny) for i in range(0,nx)]\n",
        "\n",
        "# generate a list of the positions of the links in x, y and z directions\n",
        "x_pos_links = [[.5+i,0.+j,0.+k] for k in range (0,nz) for j in range (0,ny) for i in range(0,nx)]\n",
        "y_pos_links = [[.0+i,0.5+j,0.+k] for k in range (0,nz) for j in range (0,ny) for i in range(0,nx)]\n",
        "z_pos_links = [[.0+i,0.+j,0.5+k] for k in range (0,nz) for j in range (0,ny) for i in range(0,nx)]\n",
        "\n",
        "# get list of ids for links in x, y and z directions\n",
        "x_id_links = [graph.id_from_position(pos) for pos in x_pos_links]\n",
        "x_id_links_jnp = jnp.asarray([graph.id_from_position(pos) for pos in x_pos_links])\n",
        "y_id_links = [graph.id_from_position(pos) for pos in y_pos_links]\n",
        "y_id_links_jnp = jnp.asarray([graph.id_from_position(pos) for pos in y_pos_links])\n",
        "z_id_links = [graph.id_from_position(pos) for pos in z_pos_links]\n",
        "z_id_links_jnp = jnp.asarray([graph.id_from_position(pos) for pos in z_pos_links])\n",
        "\n",
        "# generate a list of the positions of the links associated to each site\n",
        "# written for 2d at the moment, but simple to extend to higher dimensions\n",
        "site_pos_links = [[[0.5+i,0.+j,0.+k],[0.+i,0.5+j,0.+k],[0.+i,0.+j,0.5+k],[(-0.5+i) % nx,0.+j,0.+k],[0.+i,(-0.5+j) % ny,0.+k],[0.+i,0.+j,(-0.5+k) % nz]] for k in range (0,nz) for j in range (0,ny) for i in range(0,nx)]\n",
        "\n",
        "# get list of ids for links that are connected to each site\n",
        "# has form [x, y, z, -x, -y, -z]\n",
        "site_id_links = [tuple(graph.id_from_position(pos)) for pos in site_pos_links]\n",
        "site_id_links_jnp = jnp.asarray([list(graph.id_from_position(pos)) for pos in site_pos_links])\n",
        "\n",
        "# generate a list of the positions of the links that form each 1-plaquette\n",
        "# the position in the list corresponds to the node that the plaquette starts from\n",
        "plaqs_pos_links_xy = [[[0.5+i,0.+j,0.+k],[(1.+i) % nx,0.5+j,0.+k],[0.5+i,(1.+j) % ny,0.+k],[0.+i,0.5+j,0.+k]] for k in range (0,nz) for j in range (0,ny) for i in range(0,nx)]\n",
        "\n",
        "# generate a list of the positions of the links that form each 1-plaquette\n",
        "# the position in the list corresponds to the node that the plaquette starts from\n",
        "plaqs_pos_links_yz = [[[0.+i, 0.5+j, 0.+k],[0.+i, (1.+j) % ny, .5+k],[0.+i, .5 + j, (1.+k) % nz],[0.+i, 0.+j, 0.5+k]] for k in range (0,nz) for j in range (0,ny) for i in range(0,nx)]\n",
        "\n",
        "# generate a list of the positions of the links that form each 1-plaquette\n",
        "# the position in the list corresponds to the node that the plaquette starts from\n",
        "plaqs_pos_links_zx = [[[0.+i, 0.+j, 0.5+k],[0.5+i, 0.+j, (1.+k) % nz],[(1.+i) % nx, 0. + j, .5+k],[.5+i, 0.+j, 0.+k]] for k in range (0,nz) for j in range (0,ny) for i in range(0,nx)]\n",
        "\n",
        "# get list of ids for plaqs in xy, yz and zx directions\n",
        "plaqs_id_links_xy = [graph.id_from_position(pos) for pos in plaqs_pos_links_xy]\n",
        "plaqs_id_links_xy_jnp = jnp.asarray([graph.id_from_position(pos) for pos in plaqs_pos_links_xy])\n",
        "plaqs_id_links_yz = [graph.id_from_position(pos) for pos in plaqs_pos_links_yz]\n",
        "plaqs_id_links_yz_jnp = jnp.asarray([graph.id_from_position(pos) for pos in plaqs_pos_links_yz])\n",
        "plaqs_id_links_zx = [graph.id_from_position(pos) for pos in plaqs_pos_links_zx]\n",
        "plaqs_id_links_zx_jnp = jnp.asarray([graph.id_from_position(pos) for pos in plaqs_pos_links_zx])\n",
        "\n",
        "# list of ids for all plaqs - used for Hamiltonian\n",
        "plaqs_id_links = plaqs_id_links_xy + plaqs_id_links_yz + plaqs_id_links_zx"
      ],
      "metadata": {
        "id": "_ztNPFovNBSc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHM9G3ZnhS4Z"
      },
      "source": [
        "Now important Jax and generate two random states."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuH0UwpBhRch",
        "outputId": "ab8f6ca2-fc33-4bd8-9991-f6f008392e60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[gpu(id=0)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[-2., -2., -2., -2.,  0., -2.,  2., -2., -2., -2.,  0.,  2., -2.,\n",
              "         0.,  0.,  2., -2.,  0.,  2., -2.,  0., -2.,  2.,  0.,  0.,  2.,\n",
              "         0., -2., -2.,  0.,  0.,  0.,  2.,  2., -2.,  0., -2.,  0., -2.,\n",
              "        -2.,  0.,  2.,  2.,  2.,  2.,  0.,  2., -2., -2.,  2., -2.,  2.,\n",
              "        -2., -2.,  0.,  2.,  0., -2., -2., -2.,  0.,  0.,  2.,  2.,  2.,\n",
              "         2.,  2., -2.,  2., -2.,  2.,  0.,  2., -2.,  0., -2.,  0.,  0.,\n",
              "         0.,  0., -2., -2.,  2.,  0.,  2.,  0.,  2.,  2., -2.,  0., -2.,\n",
              "         0.,  0.,  0., -2.,  2.,  0.,  0., -2.,  2., -2., -2., -2., -2.,\n",
              "        -2.,  0., -2.,  0.,  0., -2.,  2., -2.,  0.,  2.,  2., -2.,  2.,\n",
              "         2.,  2.,  0.,  0.,  2.,  2.,  0., -2.,  2., -2., -2.,  0.,  0.,\n",
              "         2.,  2., -2., -2.,  2.,  2.,  0.,  0., -2.,  2.,  2.,  0.,  2.,\n",
              "         2., -2., -2., -2.,  2.,  0.,  0., -2.,  0., -2.,  2.,  0., -2.,\n",
              "         2.,  2.,  2., -2., -2.,  2., -2.,  0.,  0.,  0., -2.,  2., -2.,\n",
              "        -2.,  2.,  0.,  0., -2.,  2., -2., -2.,  0.,  2.,  0.,  2., -2.,\n",
              "         2.,  0., -2., -2.,  2.,  0.,  2., -2.,  0.,  2.,  2.,  2.,  2.,\n",
              "         0.,  2.,  0.,  2.,  0.,  2.,  0.,  2., -2.,  0., -2.,  0.,  2.,\n",
              "         2.,  2.,  0.,  0.,  0.,  2.,  2.,  2.,  0.,  0.,  0.,  2.,  2.,\n",
              "         2.,  2.,  0., -2.,  2., -2.,  0.,  0.,  2., -2.,  2., -2., -2.,\n",
              "        -2.,  2., -2.,  2.,  2.,  0.,  0.,  0.,  0., -2., -2.,  2., -2.,\n",
              "         2.,  2., -2., -2.,  2.,  0.,  2., -2.,  2.,  2.,  2., -2.,  2.,\n",
              "         0., -2., -2., -2.,  2., -2.,  0.,  2., -2.,  2.,  2.,  2., -2.,\n",
              "        -2.,  2.,  0., -2., -2., -2.,  0.,  0.,  0.,  0.,  2.,  0.,  2.,\n",
              "        -2.,  0.,  2., -2., -2.,  2., -2.,  2., -2.,  2.,  2., -2.,  2.,\n",
              "         2., -2.,  2., -2., -2., -2.,  0.,  0.,  2.,  0., -2.,  2.,  0.,\n",
              "        -2.,  2., -2.,  0., -2.,  0.,  2., -2.,  2.,  2., -2.,  0., -2.,\n",
              "        -2.,  0., -2.,  2., -2.,  0.,  2.,  0.,  2., -2.,  0.,  2.,  2.,\n",
              "         2.,  2.,  0.,  0.,  2.,  2.,  2., -2.,  2., -2.,  2.,  2.,  0.,\n",
              "        -2.,  0.,  0., -2.,  0.,  2.,  2.,  2.,  0.,  2., -2.,  2., -2.,\n",
              "         0.,  2., -2.,  0., -2.,  0., -2., -2.,  0., -2.,  0.]],      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# \"JAX will preallocate 75% of the total GPU memory when the first JAX operation is run\"\n",
        "hi.random_state(key=jax.random.PRNGKey(0), size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define some new local operators (identity matrix, clock and shift)."
      ],
      "metadata": {
        "id": "WCjy6MV2-XP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from netket.operator.spin import sigmax, sigmaz\n",
        "\n",
        "from scipy import sparse as _sparse\n",
        "\n",
        "from netket.utils.types import DType as _DType\n",
        "\n",
        "from netket.hilbert import AbstractHilbert as _AbstractHilbert\n",
        "\n",
        "from netket.operator._local_operator import LocalOperator as _LocalOperator\n",
        "\n",
        "\n",
        "def id_mat(\n",
        "    hilbert: _AbstractHilbert, site: int, dtype: _DType = float\n",
        ") -> _LocalOperator:\n",
        "    \"\"\"\n",
        "    Builds the identity matrix operator acting on the `site`-th of the Hilbert\n",
        "    space `hilbert`.\n",
        "\n",
        "    If `hilbert` is a non-Spin space of local dimension M, it is considered\n",
        "    as a (M-1)/2 - spin space.\n",
        "\n",
        "    :param hilbert: The hilbert space\n",
        "    :param site: the site on which this operator acts\n",
        "    :return: a nk.operator.LocalOperator\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    N = hilbert.size_at_index(site)\n",
        "\n",
        "    D = [1 for a in np.arange(1, N+1)]\n",
        "    mat = np.diag(D)\n",
        "    mat = _sparse.coo_matrix(mat)\n",
        "    return _LocalOperator(hilbert, mat, [site], dtype=dtype)"
      ],
      "metadata": {
        "id": "7-jL6aWWuPJf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clock and shift operators match with Q and P from 2008.00882."
      ],
      "metadata": {
        "id": "Y-r7erWh--iV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def clock(d):\n",
        "#     # Define the dth root of unity\n",
        "#     omega = np.exp(2j * np.pi / d)\n",
        "\n",
        "#     # Generate the clock matrix\n",
        "#     clock = np.diag([omega**i for i in range(d)])\n",
        "\n",
        "#     return clock\n",
        "\n",
        "# def shift(d):\n",
        "\n",
        "#     # Generate the shift matrix\n",
        "#     shift = np.zeros((d, d))\n",
        "#     shift[0, -1] = 1\n",
        "#     shift[1:, :-1] = np.eye(d - 1)\n",
        "\n",
        "#     return shift\n",
        "\n",
        "def shift(\n",
        "    hilbert: _AbstractHilbert, site: int, dtype: _DType = float\n",
        ") -> _LocalOperator:\n",
        "    \"\"\"\n",
        "    Builds the shift operator acting on the `site`-th of the Hilbert\n",
        "    space `hilbert`.\n",
        "\n",
        "    If `hilbert` is a non-Spin space of local dimension M, it is considered\n",
        "    as a (M-1)/2 - spin space.\n",
        "\n",
        "    :param hilbert: The hilbert space\n",
        "    :param site: the site on which this operator acts\n",
        "    :return: a nk.operator.LocalOperator\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    N = hilbert.size_at_index(site)\n",
        "\n",
        "    mat = np.zeros((N, N))\n",
        "    mat[0, -1] = 1\n",
        "    mat[1:, :-1] = np.eye(N - 1)\n",
        "    mat = _sparse.coo_matrix(mat)\n",
        "    return _LocalOperator(hilbert, mat, [site], dtype=dtype)\n",
        "\n",
        "def clock(\n",
        "    hilbert: _AbstractHilbert, site: int, dtype: _DType = complex\n",
        ") -> _LocalOperator:\n",
        "    \"\"\"\n",
        "    Builds the clock operator acting on the `site`-th of the Hilbert\n",
        "    space `hilbert`.\n",
        "\n",
        "    If `hilbert` is a non-Spin space of local dimension M, it is considered\n",
        "    as a (M-1)/2 - spin space.\n",
        "\n",
        "    :param hilbert: The hilbert space\n",
        "    :param site: the site on which this operator acts\n",
        "    :return: a nk.operator.LocalOperator\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    import netket.jax as nkjax\n",
        "\n",
        "    if not nkjax.is_complex_dtype(dtype):\n",
        "        import jax.numpy as jnp\n",
        "        import warnings\n",
        "\n",
        "        old_dtype = dtype\n",
        "        dtype = jnp.promote_types(complex, old_dtype)\n",
        "        warnings.warn(\n",
        "            np.ComplexWarning(\n",
        "                f\"A complex dtype is required (dtype={old_dtype} specified). \"\n",
        "                f\"Promoting to dtype={dtype}.\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "    N = hilbert.size_at_index(site)\n",
        "    # Define the N-th root of unity\n",
        "    omega = np.exp(2j * np.pi / N)\n",
        "\n",
        "    mat = np.diag([omega**i for i in range(N)])\n",
        "    mat = _sparse.coo_matrix(mat)\n",
        "    return _LocalOperator(hilbert, mat, [site], dtype=dtype)"
      ],
      "metadata": {
        "id": "2JFs72oy-A_A"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "New Hamiltonian for $\\mathbb{Z}_N$ gauge theory (from 2008.00882). Currently doesn't have the constant shift terms.\n",
        "\n",
        "Note that NetKet doesn't like putting a minus sign in front of an adjoint operator, but is fine with it outside of the brackets."
      ],
      "metadata": {
        "id": "V5z3Qdgf-qPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# g = 2.\n",
        "\n",
        "# H = - (1 / (2 * g**2)) * sum([(clock(hilbert=hi, site=i).H * clock(hilbert=hi, site=j).H *\n",
        "#          clock(hilbert=hi, site=k) * clock(hilbert=hi, site=l) + clock(hilbert=hi, site=l).H * clock(hilbert=hi, site=k).H *\n",
        "#          clock(hilbert=hi, site=j) * clock(hilbert=hi, site=i)) for (i,j,k,l) in plaqs_id_links])\n",
        "\n",
        "# H = H - ((g**2) / 2) * sum([(shift(hilbert=hi, site=i) + shift(hilbert=hi, site=i).H) for i in range(N)])"
      ],
      "metadata": {
        "id": "8wDJaAMs_q0h"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now with shift terms (moves energy by $+L^2 (g^2 + 1/g^2)$)."
      ],
      "metadata": {
        "id": "JlkFWd6dDmO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = 2.\n",
        "\n",
        "H = - (1 / (2 * g**2)) * sum([(- 2 * id_mat(hilbert=hi, site=i)*id_mat(hilbert=hi, site=j)*\n",
        "            id_mat(hilbert=hi, site=k)*id_mat(hilbert=hi, site=l) + clock(hilbert=hi, site=i).H * clock(hilbert=hi, site=j).H *\n",
        "         clock(hilbert=hi, site=k) * clock(hilbert=hi, site=l) + clock(hilbert=hi, site=l).H * clock(hilbert=hi, site=k).H *\n",
        "         clock(hilbert=hi, site=j) * clock(hilbert=hi, site=i)) for (i,j,k,l) in plaqs_id_links])\n",
        "\n",
        "H = H - ((g**2) / 2) * sum([(- 2 * id_mat(hilbert=hi, site=i) + shift(hilbert=hi, site=i) + shift(hilbert=hi, site=i).H) for i in range(N)])"
      ],
      "metadata": {
        "id": "NkqqHtErDl0Q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\mathbb{Z}_N$ gauge operator. Define $\\Theta_x = P_{x,\\mu} P_{x,\\nu} P^\\dagger_{x-\\mu,\\mu} P^\\dagger_{x-\\nu,\\nu}$. The gauge invariance condition is then $\\Theta_x |\\Psi\\rangle = \\pm |\\Psi\\rangle$ with the same choice of sign for all $x$. We can then impose this as a positive definite condition as $(\\Theta-1)(\\Theta^\\dagger - 1) = $ on gauge invariant states."
      ],
      "metadata": {
        "id": "qr0h3CImn2F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# should give +-L^2\n",
        "gauge = sum([shift(hilbert=hi, site=i)*shift(hilbert=hi, site=j)*shift(hilbert=hi, site=k)*(shift(hilbert=hi, site=l).H)*(shift(hilbert=hi, site=m).H)*(shift(hilbert=hi, site=n).H) for (i,j,k,l,m,n) in site_id_links])\n",
        "\n",
        "# should give 0\n",
        "gauge_zero = sum([(shift(hilbert=hi, site=i)*shift(hilbert=hi, site=j)*shift(hilbert=hi, site=k)*(shift(hilbert=hi, site=l).H)*(shift(hilbert=hi, site=m).H)*(shift(hilbert=hi, site=n).H)-id_mat(hilbert=hi, site=i)*id_mat(hilbert=hi, site=j)*\n",
        "            id_mat(hilbert=hi, site=k)*id_mat(hilbert=hi, site=l)*id_mat(hilbert=hi, site=m)*id_mat(hilbert=hi, site=n))*(shift(hilbert=hi, site=n)*shift(hilbert=hi, site=m)*shift(hilbert=hi, site=l)*(shift(hilbert=hi, site=k).H)*(shift(hilbert=hi, site=j).H)*(shift(hilbert=hi, site=i).H)\n",
        "            -id_mat(hilbert=hi, site=i)*id_mat(hilbert=hi, site=j)*id_mat(hilbert=hi, site=k)*id_mat(hilbert=hi, site=l)*id_mat(hilbert=hi, site=m)*id_mat(hilbert=hi, site=n)) for (i,j,k,l,m,n) in site_id_links])"
      ],
      "metadata": {
        "id": "ZfQVr6Itn1mU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLlR2vbijZBs"
      },
      "source": [
        "## Exact diagonalisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mnye9_Gj_Q1"
      },
      "source": [
        "We can start by trying exact diagonalisation. This works by converting the Hamiltonian operator in a sparse matrix of size $2^{N^2} \\times 2^{N^2} = 1024 \\times 1024$. This is just a standard scipy sparse matrix, so we can use any (sparse) matrix diagonalisation routine to find the eigensystem. For example, we can find the two lowest eigenstates via:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ES1aXWvIj8QV"
      },
      "outputs": [],
      "source": [
        "# eig_vals, eig_vecs = nk.exact.lanczos_ed(H, k=1, compute_eigenvectors=True)\n",
        "\n",
        "# print(\"Eigenvalues with sparse solver:\", eig_vals)\n",
        "\n",
        "# E_gs = eig_vals[0]\n",
        "\n",
        "# print(\"Approx energy per site:\", [E/(nx * ny) for E in  eig_vals_penalty])\n",
        "\n",
        "# eig_vals_penalty, eig_vecs_penalty = nk.exact.lanczos_ed(H_penalty, k=1, compute_eigenvectors=True)\n",
        "\n",
        "# print(\"Eigenvalues with gauge penalty with sparse solver:\", eig_vals_penalty)\n",
        "\n",
        "# print(\"Approx energy per site:\", [(E - penalty * nx * ny)/(nx * ny) for E in  eig_vals_penalty])\n",
        "\n",
        "# E_gs_penalty = eig_vals_penalty[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql5eFRXplKjE"
      },
      "source": [
        "## Neural network quantum state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rBUvfGbxka0U"
      },
      "outputs": [],
      "source": [
        "# numerical operations in the model should always use jax.numpy\n",
        "# instead of numpy because jax supports computing derivatives.\n",
        "# If you want to better understand the difference between the two, check\n",
        "# https://flax.readthedocs.io/en/latest/notebooks/jax_for_the_impatient.html\n",
        "import jax.numpy as jnp\n",
        "\n",
        "# Flax is a framework to define models using jax\n",
        "import flax\n",
        "\n",
        "# we refer to `flax.linen` as `nn`. It's a repository of\n",
        "# layers, initializers and nonlinear functions.\n",
        "import flax.linen as nn\n",
        "\n",
        "from typing import Any, Callable, Sequence\n",
        "from jax import lax, random\n",
        "from flax.core import freeze, unfreeze"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Functions for converting from spins to $\\mathbb{Z}_N$ phases."
      ],
      "metadata": {
        "id": "HqQBoGagJ84n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions to convert a spin state to $\\mathbb{Z}_N$ phases. By working with the phases, this should generalise more easily to non-abelian groups."
      ],
      "metadata": {
        "id": "99Pk4GAzcCAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert a state, given by an array of spins, to Z_N elements\n",
        "# e.g. spins (1,-1) -> (1,0), or (1,0,-1) -> (2,1,0)\n",
        "# and then take exp(..2 i pi / N) to get the Z_N phase\n",
        "# for what follows, we assume that the phases are directed such that the\n",
        "# non-daggered phases are those on links leading away from the origin\n",
        "@jax.jit\n",
        "def spins_to_links(state, N):\n",
        "    links = (state + (N-1.)) / 2\n",
        "    links = jnp.exp(2 * jnp.pi * 1j * links / N)\n",
        "    return links\n",
        "\n",
        "\n",
        "# single state is an array\n",
        "x = hi.random_state(key=jax.random.PRNGKey(0))\n",
        "print(x)\n",
        "print(spins_to_links(x, 2))"
      ],
      "metadata": {
        "id": "SZ4fBFm5XIEY",
        "outputId": "59f980b0-d6ec-4913-b14f-e18a8f05b547",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-2. -2. -2. -2.  0. -2.  2. -2. -2. -2.  0.  2. -2.  0.  0.  2. -2.  0.\n",
            "  2. -2.  0. -2.  2.  0.  0.  2.  0. -2. -2.  0.  0.  0.  2.  2. -2.  0.\n",
            " -2.  0. -2. -2.  0.  2.  2.  2.  2.  0.  2. -2. -2.  2. -2.  2. -2. -2.\n",
            "  0.  2.  0. -2. -2. -2.  0.  0.  2.  2.  2.  2.  2. -2.  2. -2.  2.  0.\n",
            "  2. -2.  0. -2.  0.  0.  0.  0. -2. -2.  2.  0.  2.  0.  2.  2. -2.  0.\n",
            " -2.  0.  0.  0. -2.  2.  0.  0. -2.  2. -2. -2. -2. -2. -2.  0. -2.  0.\n",
            "  0. -2.  2. -2.  0.  2.  2. -2.  2.  2.  2.  0.  0.  2.  2.  0. -2.  2.\n",
            " -2. -2.  0.  0.  2.  2. -2. -2.  2.  2.  0.  0. -2.  2.  2.  0.  2.  2.\n",
            " -2. -2. -2.  2.  0.  0. -2.  0. -2.  2.  0. -2.  2.  2.  2. -2. -2.  2.\n",
            " -2.  0.  0.  0. -2.  2. -2. -2.  2.  0.  0. -2.  2. -2. -2.  0.  2.  0.\n",
            "  2. -2.  2.  0. -2. -2.  2.  0.  2. -2.  0.  2.  2.  2.  2.  0.  2.  0.\n",
            "  2.  0.  2.  0.  2. -2.  0. -2.  0.  2.  2.  2.  0.  0.  0.  2.  2.  2.\n",
            "  0.  0.  0.  2.  2.  2.  2.  0. -2.  2. -2.  0.  0.  2. -2.  2. -2. -2.\n",
            " -2.  2. -2.  2.  2.  0.  0.  0.  0. -2. -2.  2. -2.  2.  2. -2. -2.  2.\n",
            "  0.  2. -2.  2.  2.  2. -2.  2.  0. -2. -2. -2.  2. -2.  0.  2. -2.  2.\n",
            "  2.  2. -2. -2.  2.  0. -2. -2. -2.  0.  0.  0.  0.  2.  0.  2. -2.  0.\n",
            "  2. -2. -2.  2. -2.  2. -2.  2.  2. -2.  2.  2. -2.  2. -2. -2. -2.  0.\n",
            "  0.  2.  0. -2.  2.  0. -2.  2. -2.  0. -2.  0.  2. -2.  2.  2. -2.  0.\n",
            " -2. -2.  0. -2.  2. -2.  0.  2.  0.  2. -2.  0.  2.  2.  2.  2.  0.  0.\n",
            "  2.  2.  2. -2.  2. -2.  2.  2.  0. -2.  0.  0. -2.  0.  2.  2.  2.  0.\n",
            "  2. -2.  2. -2.  0.  2. -2.  0. -2.  0. -2. -2.  0. -2.  0.]\n",
            "[-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "  1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "  1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "  1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08+1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08+1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08+1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "  1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "  1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "  1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "  1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "  1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "  1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "  1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "  1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "  1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "  1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "  1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "  1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "  1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            " -4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            " -4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to convert a batch of spin states to $\\mathbb{Z}_N$ phases."
      ],
      "metadata": {
        "id": "Xh7zb9hvJGuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use vmap to batch generation of Z_N phases over an array of states\n",
        "@jax.jit\n",
        "def spins_to_links_batched(state_batched, N):\n",
        "    return jax.vmap(spins_to_links, in_axes=(0,None), out_axes=0)(state_batched, N)\n",
        "\n",
        "\n",
        "# when you specify the size, you get a array of arrays\n",
        "x = hi.random_state(key=jax.random.PRNGKey(0), size=1)\n",
        "print(x)\n",
        "print(spins_to_links_batched(x, 2))"
      ],
      "metadata": {
        "id": "kuSo7UOEajF3",
        "outputId": "7c5e8ae3-1da2-4ca4-dccd-0651cc314f36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-2. -2. -2. -2.  0. -2.  2. -2. -2. -2.  0.  2. -2.  0.  0.  2. -2.  0.\n",
            "   2. -2.  0. -2.  2.  0.  0.  2.  0. -2. -2.  0.  0.  0.  2.  2. -2.  0.\n",
            "  -2.  0. -2. -2.  0.  2.  2.  2.  2.  0.  2. -2. -2.  2. -2.  2. -2. -2.\n",
            "   0.  2.  0. -2. -2. -2.  0.  0.  2.  2.  2.  2.  2. -2.  2. -2.  2.  0.\n",
            "   2. -2.  0. -2.  0.  0.  0.  0. -2. -2.  2.  0.  2.  0.  2.  2. -2.  0.\n",
            "  -2.  0.  0.  0. -2.  2.  0.  0. -2.  2. -2. -2. -2. -2. -2.  0. -2.  0.\n",
            "   0. -2.  2. -2.  0.  2.  2. -2.  2.  2.  2.  0.  0.  2.  2.  0. -2.  2.\n",
            "  -2. -2.  0.  0.  2.  2. -2. -2.  2.  2.  0.  0. -2.  2.  2.  0.  2.  2.\n",
            "  -2. -2. -2.  2.  0.  0. -2.  0. -2.  2.  0. -2.  2.  2.  2. -2. -2.  2.\n",
            "  -2.  0.  0.  0. -2.  2. -2. -2.  2.  0.  0. -2.  2. -2. -2.  0.  2.  0.\n",
            "   2. -2.  2.  0. -2. -2.  2.  0.  2. -2.  0.  2.  2.  2.  2.  0.  2.  0.\n",
            "   2.  0.  2.  0.  2. -2.  0. -2.  0.  2.  2.  2.  0.  0.  0.  2.  2.  2.\n",
            "   0.  0.  0.  2.  2.  2.  2.  0. -2.  2. -2.  0.  0.  2. -2.  2. -2. -2.\n",
            "  -2.  2. -2.  2.  2.  0.  0.  0.  0. -2. -2.  2. -2.  2.  2. -2. -2.  2.\n",
            "   0.  2. -2.  2.  2.  2. -2.  2.  0. -2. -2. -2.  2. -2.  0.  2. -2.  2.\n",
            "   2.  2. -2. -2.  2.  0. -2. -2. -2.  0.  0.  0.  0.  2.  0.  2. -2.  0.\n",
            "   2. -2. -2.  2. -2.  2. -2.  2.  2. -2.  2.  2. -2.  2. -2. -2. -2.  0.\n",
            "   0.  2.  0. -2.  2.  0. -2.  2. -2.  0. -2.  0.  2. -2.  2.  2. -2.  0.\n",
            "  -2. -2.  0. -2.  2. -2.  0.  2.  0.  2. -2.  0.  2.  2.  2.  2.  0.  0.\n",
            "   2.  2.  2. -2.  2. -2.  2.  2.  0. -2.  0.  0. -2.  0.  2.  2.  2.  0.\n",
            "   2. -2.  2. -2.  0.  2. -2.  0. -2.  0. -2. -2.  0. -2.  0.]]\n",
            "[[-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "   1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "   1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "   1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08+1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08+1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08+1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "   1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "   1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "   1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "   1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "   1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "   1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "   1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "   1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "   1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "   1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "   1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "   1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "   1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "  -4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "  -4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Functions to converting from vector of links to tensor"
      ],
      "metadata": {
        "id": "t4bPNo9O3psg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert a list of the link variables, indexed by the edge labels on the graph\n",
        "# to an (dim,nx,ny,nz) tensor\n",
        "# the first index labels whether you are picking the x, y or z links\n",
        "# the second and third index label the (x,y,z) coordinates of the associated node\n",
        "@jax.jit\n",
        "def links_to_tensor(links):\n",
        "    x_links = links[x_id_links_jnp]\n",
        "    y_links = links[y_id_links_jnp]\n",
        "    z_links = links[z_id_links_jnp]\n",
        "    xyz_links = jnp.stack((x_links, y_links,z_links), axis=0)\n",
        "    return jnp.reshape(xyz_links,(3, nx, ny, nz), order=\"F\")\n",
        "\n",
        "x = jnp.asarray(range(2 * nx * ny * nz))\n",
        "print(x)\n",
        "print(links_to_tensor(x))\n",
        "print(links_to_tensor(x).shape)\n",
        "print(links_to_tensor(x)[1,0,0,1])\n",
        "print(links_to_tensor(x)[0,0,0,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ghygA8I3u8-",
        "outputId": "ef1efe5c-f0dc-400a-d966-91d16af8471d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249]\n",
            "[[[[  0  75 150 225 249]\n",
            "   [ 15  90 165 240 249]\n",
            "   [ 30 105 180 249 249]\n",
            "   [ 45 120 195 249 249]\n",
            "   [ 60 135 210 249 249]]\n",
            "\n",
            "  [[  3  78 153 228 249]\n",
            "   [ 18  93 168 243 249]\n",
            "   [ 33 108 183 249 249]\n",
            "   [ 48 123 198 249 249]\n",
            "   [ 63 138 213 249 249]]\n",
            "\n",
            "  [[  6  81 156 231 249]\n",
            "   [ 21  96 171 246 249]\n",
            "   [ 36 111 186 249 249]\n",
            "   [ 51 126 201 249 249]\n",
            "   [ 66 141 216 249 249]]\n",
            "\n",
            "  [[  9  84 159 234 249]\n",
            "   [ 24  99 174 249 249]\n",
            "   [ 39 114 189 249 249]\n",
            "   [ 54 129 204 249 249]\n",
            "   [ 69 144 219 249 249]]\n",
            "\n",
            "  [[ 12  87 162 237 249]\n",
            "   [ 27 102 177 249 249]\n",
            "   [ 42 117 192 249 249]\n",
            "   [ 57 132 207 249 249]\n",
            "   [ 72 147 222 249 249]]]\n",
            "\n",
            "\n",
            " [[[  1  76 151 226 249]\n",
            "   [ 16  91 166 241 249]\n",
            "   [ 31 106 181 249 249]\n",
            "   [ 46 121 196 249 249]\n",
            "   [ 61 136 211 249 249]]\n",
            "\n",
            "  [[  4  79 154 229 249]\n",
            "   [ 19  94 169 244 249]\n",
            "   [ 34 109 184 249 249]\n",
            "   [ 49 124 199 249 249]\n",
            "   [ 64 139 214 249 249]]\n",
            "\n",
            "  [[  7  82 157 232 249]\n",
            "   [ 22  97 172 247 249]\n",
            "   [ 37 112 187 249 249]\n",
            "   [ 52 127 202 249 249]\n",
            "   [ 67 142 217 249 249]]\n",
            "\n",
            "  [[ 10  85 160 235 249]\n",
            "   [ 25 100 175 249 249]\n",
            "   [ 40 115 190 249 249]\n",
            "   [ 55 130 205 249 249]\n",
            "   [ 70 145 220 249 249]]\n",
            "\n",
            "  [[ 13  88 163 238 249]\n",
            "   [ 28 103 178 249 249]\n",
            "   [ 43 118 193 249 249]\n",
            "   [ 58 133 208 249 249]\n",
            "   [ 73 148 223 249 249]]]\n",
            "\n",
            "\n",
            " [[[  2  77 152 227 249]\n",
            "   [ 17  92 167 242 249]\n",
            "   [ 32 107 182 249 249]\n",
            "   [ 47 122 197 249 249]\n",
            "   [ 62 137 212 249 249]]\n",
            "\n",
            "  [[  5  80 155 230 249]\n",
            "   [ 20  95 170 245 249]\n",
            "   [ 35 110 185 249 249]\n",
            "   [ 50 125 200 249 249]\n",
            "   [ 65 140 215 249 249]]\n",
            "\n",
            "  [[  8  83 158 233 249]\n",
            "   [ 23  98 173 248 249]\n",
            "   [ 38 113 188 249 249]\n",
            "   [ 53 128 203 249 249]\n",
            "   [ 68 143 218 249 249]]\n",
            "\n",
            "  [[ 11  86 161 236 249]\n",
            "   [ 26 101 176 249 249]\n",
            "   [ 41 116 191 249 249]\n",
            "   [ 56 131 206 249 249]\n",
            "   [ 71 146 221 249 249]]\n",
            "\n",
            "  [[ 14  89 164 239 249]\n",
            "   [ 29 104 179 249 249]\n",
            "   [ 44 119 194 249 249]\n",
            "   [ 59 134 209 249 249]\n",
            "   [ 74 149 224 249 249]]]]\n",
            "(3, 5, 5, 5)\n",
            "76\n",
            "75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert a list of the link variables, indexed by the edge labels on the graph\n",
        "# to an (dim,nx,ny) tensor\n",
        "# the first index labels whether you are picking the x or the y links\n",
        "# the second and third index label the (x,y) coordinates of the associated node\n",
        "@jax.jit\n",
        "def links_to_tensor_batched(links_batched):\n",
        "    return jax.vmap(links_to_tensor, in_axes=(0), out_axes=0)(links_batched)\n",
        "\n",
        "x = jnp.asarray([jnp.asarray(range(2 * nx * ny * nz))])\n",
        "print(x)\n",
        "print(links_to_tensor_batched(x))\n",
        "print(links_to_tensor_batched(x).shape)\n",
        "print(links_to_tensor_batched(x)[0,1,0,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5Ta8iXx3zsV",
        "outputId": "57003856-c339-42bf-c924-0b0677751de4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            "  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            "  126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            "  144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            "  162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            "  180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            "  198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            "  216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            "  234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249]]\n",
            "[[[[[  0  75 150 225 249]\n",
            "    [ 15  90 165 240 249]\n",
            "    [ 30 105 180 249 249]\n",
            "    [ 45 120 195 249 249]\n",
            "    [ 60 135 210 249 249]]\n",
            "\n",
            "   [[  3  78 153 228 249]\n",
            "    [ 18  93 168 243 249]\n",
            "    [ 33 108 183 249 249]\n",
            "    [ 48 123 198 249 249]\n",
            "    [ 63 138 213 249 249]]\n",
            "\n",
            "   [[  6  81 156 231 249]\n",
            "    [ 21  96 171 246 249]\n",
            "    [ 36 111 186 249 249]\n",
            "    [ 51 126 201 249 249]\n",
            "    [ 66 141 216 249 249]]\n",
            "\n",
            "   [[  9  84 159 234 249]\n",
            "    [ 24  99 174 249 249]\n",
            "    [ 39 114 189 249 249]\n",
            "    [ 54 129 204 249 249]\n",
            "    [ 69 144 219 249 249]]\n",
            "\n",
            "   [[ 12  87 162 237 249]\n",
            "    [ 27 102 177 249 249]\n",
            "    [ 42 117 192 249 249]\n",
            "    [ 57 132 207 249 249]\n",
            "    [ 72 147 222 249 249]]]\n",
            "\n",
            "\n",
            "  [[[  1  76 151 226 249]\n",
            "    [ 16  91 166 241 249]\n",
            "    [ 31 106 181 249 249]\n",
            "    [ 46 121 196 249 249]\n",
            "    [ 61 136 211 249 249]]\n",
            "\n",
            "   [[  4  79 154 229 249]\n",
            "    [ 19  94 169 244 249]\n",
            "    [ 34 109 184 249 249]\n",
            "    [ 49 124 199 249 249]\n",
            "    [ 64 139 214 249 249]]\n",
            "\n",
            "   [[  7  82 157 232 249]\n",
            "    [ 22  97 172 247 249]\n",
            "    [ 37 112 187 249 249]\n",
            "    [ 52 127 202 249 249]\n",
            "    [ 67 142 217 249 249]]\n",
            "\n",
            "   [[ 10  85 160 235 249]\n",
            "    [ 25 100 175 249 249]\n",
            "    [ 40 115 190 249 249]\n",
            "    [ 55 130 205 249 249]\n",
            "    [ 70 145 220 249 249]]\n",
            "\n",
            "   [[ 13  88 163 238 249]\n",
            "    [ 28 103 178 249 249]\n",
            "    [ 43 118 193 249 249]\n",
            "    [ 58 133 208 249 249]\n",
            "    [ 73 148 223 249 249]]]\n",
            "\n",
            "\n",
            "  [[[  2  77 152 227 249]\n",
            "    [ 17  92 167 242 249]\n",
            "    [ 32 107 182 249 249]\n",
            "    [ 47 122 197 249 249]\n",
            "    [ 62 137 212 249 249]]\n",
            "\n",
            "   [[  5  80 155 230 249]\n",
            "    [ 20  95 170 245 249]\n",
            "    [ 35 110 185 249 249]\n",
            "    [ 50 125 200 249 249]\n",
            "    [ 65 140 215 249 249]]\n",
            "\n",
            "   [[  8  83 158 233 249]\n",
            "    [ 23  98 173 248 249]\n",
            "    [ 38 113 188 249 249]\n",
            "    [ 53 128 203 249 249]\n",
            "    [ 68 143 218 249 249]]\n",
            "\n",
            "   [[ 11  86 161 236 249]\n",
            "    [ 26 101 176 249 249]\n",
            "    [ 41 116 191 249 249]\n",
            "    [ 56 131 206 249 249]\n",
            "    [ 71 146 221 249 249]]\n",
            "\n",
            "   [[ 14  89 164 239 249]\n",
            "    [ 29 104 179 249 249]\n",
            "    [ 44 119 194 249 249]\n",
            "    [ 59 134 209 249 249]\n",
            "    [ 74 149 224 249 249]]]]]\n",
            "(1, 3, 5, 5, 5)\n",
            "[ 16  91 166 241 249]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "New Flax layer which converts a batch of vectors of spin states and returns a batch of $\\mathbb{Z}_N$ phases.\n",
        "\n",
        "Input: (n_batch, spin_states_vector)\n",
        "Output: (n_batch, 0 or 1, x coord, y coord)\n",
        "\n",
        "The spin_states_vector links are numbered according to the Netket graph.\n",
        "\n",
        "In the output, we convert this to a tensor, with 0 or 1 labelling whether we are looking at the x links or the y links, and the x and y coords labelling the node associated to those links (links leave node in positive x or y direction)."
      ],
      "metadata": {
        "id": "2v1-bXkM6JLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A Flax model must be a class subclassing `nn.Module`\n",
        "# The most compact way to define the model is this.\n",
        "# The __call__(self, x) function should take as\n",
        "# input a batch of states shape = (n_batch, spin_states_vector)\n",
        "# and should return (n_batch, 0 or 1 or 2, x coord, y coord, z coord)\n",
        "# where the coords refer to the node to which the links are associated\n",
        "class ZN_to_Phase(nn.Module):\n",
        "\n",
        "    # You can define attributes at the module-level\n",
        "    # with a default. This allows you to easily change\n",
        "    # some hyper-parameter without redefining the whole\n",
        "    # flax module.\n",
        "    N: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "\n",
        "        links_vector_batch = spins_to_links_batched(x, self.N)\n",
        "        links_tensor_batch = links_to_tensor_batched(links_vector_batch)\n",
        "\n",
        "        # return the output\n",
        "        return links_tensor_batch\n",
        "\n",
        "# Create an instance of the model.\n",
        "model_1 = ZN_to_Phase(N=2)\n",
        "\n",
        "# Create the local sampler on the hilbert space\n",
        "#sampler = nk.sampler.MetropolisLocal(hi)\n",
        "\n",
        "# Construct the variational state using the model and the sampler above.\n",
        "# n_samples specifies how many samples should be used to compute expectation\n",
        "# values.\n",
        "#vstate = nk.vqs.MCState(sampler, model, n_samples=1000)\n",
        "\n",
        "#vstate.n_parameters\n",
        "\n",
        "x = hi.random_state(key=jax.random.PRNGKey(0), size=1)\n",
        "\n",
        "key1, key2 = random.split(random.PRNGKey(0))\n",
        "params_1 = model_1.init(key1, x) # Initialization call\n",
        "# jax.tree_util.tree_map(lambda x: x.shape, params) # Checking output shapes\n",
        "\n",
        "print(x)\n",
        "print(links_to_tensor_batched(spins_to_links_batched(x, 2)))\n",
        "print(model_1.apply(params_1, x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6A4_XhT46hd",
        "outputId": "11ec77fc-f598-4749-c827-c1d6ab2ef4d7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-2. -2. -2. -2.  0. -2.  2. -2. -2. -2.  0.  2. -2.  0.  0.  2. -2.  0.\n",
            "   2. -2.  0. -2.  2.  0.  0.  2.  0. -2. -2.  0.  0.  0.  2.  2. -2.  0.\n",
            "  -2.  0. -2. -2.  0.  2.  2.  2.  2.  0.  2. -2. -2.  2. -2.  2. -2. -2.\n",
            "   0.  2.  0. -2. -2. -2.  0.  0.  2.  2.  2.  2.  2. -2.  2. -2.  2.  0.\n",
            "   2. -2.  0. -2.  0.  0.  0.  0. -2. -2.  2.  0.  2.  0.  2.  2. -2.  0.\n",
            "  -2.  0.  0.  0. -2.  2.  0.  0. -2.  2. -2. -2. -2. -2. -2.  0. -2.  0.\n",
            "   0. -2.  2. -2.  0.  2.  2. -2.  2.  2.  2.  0.  0.  2.  2.  0. -2.  2.\n",
            "  -2. -2.  0.  0.  2.  2. -2. -2.  2.  2.  0.  0. -2.  2.  2.  0.  2.  2.\n",
            "  -2. -2. -2.  2.  0.  0. -2.  0. -2.  2.  0. -2.  2.  2.  2. -2. -2.  2.\n",
            "  -2.  0.  0.  0. -2.  2. -2. -2.  2.  0.  0. -2.  2. -2. -2.  0.  2.  0.\n",
            "   2. -2.  2.  0. -2. -2.  2.  0.  2. -2.  0.  2.  2.  2.  2.  0.  2.  0.\n",
            "   2.  0.  2.  0.  2. -2.  0. -2.  0.  2.  2.  2.  0.  0.  0.  2.  2.  2.\n",
            "   0.  0.  0.  2.  2.  2.  2.  0. -2.  2. -2.  0.  0.  2. -2.  2. -2. -2.\n",
            "  -2.  2. -2.  2.  2.  0.  0.  0.  0. -2. -2.  2. -2.  2.  2. -2. -2.  2.\n",
            "   0.  2. -2.  2.  2.  2. -2.  2.  0. -2. -2. -2.  2. -2.  0.  2. -2.  2.\n",
            "   2.  2. -2. -2.  2.  0. -2. -2. -2.  0.  0.  0.  0.  2.  0.  2. -2.  0.\n",
            "   2. -2. -2.  2. -2.  2. -2.  2.  2. -2.  2.  2. -2.  2. -2. -2. -2.  0.\n",
            "   0.  2.  0. -2.  2.  0. -2.  2. -2.  0. -2.  0.  2. -2.  2.  2. -2.  0.\n",
            "  -2. -2.  0. -2.  2. -2.  0.  2.  0.  2. -2.  0.  2.  2.  2.  2.  0.  0.\n",
            "   2.  2.  2. -2.  2. -2.  2.  2.  0. -2.  0.  0. -2.  0.  2.  2.  2.  0.\n",
            "   2. -2.  2. -2.  0.  2. -2.  0. -2.  0. -2. -2.  0. -2.  0.]]\n",
            "[[[[[-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]]\n",
            "\n",
            "   [[ 1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]]]\n",
            "\n",
            "\n",
            "  [[[-4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]]\n",
            "\n",
            "   [[-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]]]\n",
            "\n",
            "\n",
            "  [[[-4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]]\n",
            "\n",
            "   [[ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]]]]]\n",
            "[[[[[-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]]\n",
            "\n",
            "   [[ 1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]]]\n",
            "\n",
            "\n",
            "  [[[-4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]]\n",
            "\n",
            "   [[-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]]]\n",
            "\n",
            "\n",
            "  [[[-4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]]\n",
            "\n",
            "   [[ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Functions for computing plaquette variables"
      ],
      "metadata": {
        "id": "i6rmoZw0KDJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate all xy plaquettes\n",
        "@jax.jit\n",
        "def tensor_links_to_plaqs_xy(tensor_links):\n",
        "    # mu = xhat, nu = yhat\n",
        "    # U_x,mu - select x links\n",
        "    U_x_mu = tensor_links[0]\n",
        "    # U_x,nu - select y links\n",
        "    U_x_nu = tensor_links[1]\n",
        "    # U_x+mu,nu\n",
        "    U_x_mu_nu = jnp.roll(U_x_nu, (-1, 0, 0), axis=(0,1,2))\n",
        "    # U_x+nu,mu\n",
        "    U_x_nu_mu = jnp.roll(U_x_mu, (0, -1, 0), axis=(0,1,2))\n",
        "    # plaq_x = U_x,mu * U_x+mu,nu * dag(U_x+nu,mu) * dag(U_x,nu)\n",
        "    return jnp.multiply(jnp.multiply(U_x_mu, U_x_mu_nu), jnp.multiply(jnp.conj(U_x_nu_mu), jnp.conj(U_x_nu)))\n",
        "\n",
        "# calculate all xy plaquettes\n",
        "@jax.jit\n",
        "def tensor_links_to_plaqs_yz(tensor_links):\n",
        "    # mu = yhat, nu = zhat\n",
        "    # U_x,mu - select y links\n",
        "    U_x_mu = tensor_links[1]\n",
        "    # U_x,nu - select z links\n",
        "    U_x_nu = tensor_links[2]\n",
        "    # U_x+mu,nu\n",
        "    U_x_mu_nu = jnp.roll(U_x_nu, (0, -1, 0), axis=(0,1,2))\n",
        "    # U_x+nu,mu\n",
        "    U_x_nu_mu = jnp.roll(U_x_mu, (0, 0, -1), axis=(0,1,2))\n",
        "    # plaq_x = U_x,mu * U_x+mu,nu * dag(U_x+nu,mu) * dag(U_x,nu)\n",
        "    return jnp.multiply(jnp.multiply(U_x_mu, U_x_mu_nu), jnp.multiply(jnp.conj(U_x_nu_mu), jnp.conj(U_x_nu)))\n",
        "\n",
        "# calculate all xy plaquettes\n",
        "@jax.jit\n",
        "def tensor_links_to_plaqs_zx(tensor_links):\n",
        "    # mu = zhat, nu = xhat\n",
        "    # U_x,mu - select x links\n",
        "    U_x_mu = tensor_links[2]\n",
        "    # U_x,nu - select y links\n",
        "    U_x_nu = tensor_links[0]\n",
        "    # U_x+mu,nu\n",
        "    U_x_mu_nu = jnp.roll(U_x_nu, (0, 0, -1), axis=(0,1,2))\n",
        "    # U_x+nu,mu\n",
        "    U_x_nu_mu = jnp.roll(U_x_mu, (-1, 0, 0), axis=(0,1,2))\n",
        "    # plaq_x = U_x,mu * U_x+mu,nu * dag(U_x+nu,mu) * dag(U_x,nu)\n",
        "    return jnp.multiply(jnp.multiply(U_x_mu, U_x_mu_nu), jnp.multiply(jnp.conj(U_x_nu_mu), jnp.conj(U_x_nu)))\n",
        "\n",
        "\n",
        "# example\n",
        "x = jnp.asarray(range(2 * nx * ny * nz))\n",
        "print(x)\n",
        "print(links_to_tensor(x))\n",
        "\n",
        "tensor_links_to_plaqs_xy(links_to_tensor(x))[1,1]"
      ],
      "metadata": {
        "id": "-Zu8pVoqiVa8",
        "outputId": "d3785e48-051d-4654-b2f4-41ded308512a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249]\n",
            "[[[[  0  75 150 225 249]\n",
            "   [ 15  90 165 240 249]\n",
            "   [ 30 105 180 249 249]\n",
            "   [ 45 120 195 249 249]\n",
            "   [ 60 135 210 249 249]]\n",
            "\n",
            "  [[  3  78 153 228 249]\n",
            "   [ 18  93 168 243 249]\n",
            "   [ 33 108 183 249 249]\n",
            "   [ 48 123 198 249 249]\n",
            "   [ 63 138 213 249 249]]\n",
            "\n",
            "  [[  6  81 156 231 249]\n",
            "   [ 21  96 171 246 249]\n",
            "   [ 36 111 186 249 249]\n",
            "   [ 51 126 201 249 249]\n",
            "   [ 66 141 216 249 249]]\n",
            "\n",
            "  [[  9  84 159 234 249]\n",
            "   [ 24  99 174 249 249]\n",
            "   [ 39 114 189 249 249]\n",
            "   [ 54 129 204 249 249]\n",
            "   [ 69 144 219 249 249]]\n",
            "\n",
            "  [[ 12  87 162 237 249]\n",
            "   [ 27 102 177 249 249]\n",
            "   [ 42 117 192 249 249]\n",
            "   [ 57 132 207 249 249]\n",
            "   [ 72 147 222 249 249]]]\n",
            "\n",
            "\n",
            " [[[  1  76 151 226 249]\n",
            "   [ 16  91 166 241 249]\n",
            "   [ 31 106 181 249 249]\n",
            "   [ 46 121 196 249 249]\n",
            "   [ 61 136 211 249 249]]\n",
            "\n",
            "  [[  4  79 154 229 249]\n",
            "   [ 19  94 169 244 249]\n",
            "   [ 34 109 184 249 249]\n",
            "   [ 49 124 199 249 249]\n",
            "   [ 64 139 214 249 249]]\n",
            "\n",
            "  [[  7  82 157 232 249]\n",
            "   [ 22  97 172 247 249]\n",
            "   [ 37 112 187 249 249]\n",
            "   [ 52 127 202 249 249]\n",
            "   [ 67 142 217 249 249]]\n",
            "\n",
            "  [[ 10  85 160 235 249]\n",
            "   [ 25 100 175 249 249]\n",
            "   [ 40 115 190 249 249]\n",
            "   [ 55 130 205 249 249]\n",
            "   [ 70 145 220 249 249]]\n",
            "\n",
            "  [[ 13  88 163 238 249]\n",
            "   [ 28 103 178 249 249]\n",
            "   [ 43 118 193 249 249]\n",
            "   [ 58 133 208 249 249]\n",
            "   [ 73 148 223 249 249]]]\n",
            "\n",
            "\n",
            " [[[  2  77 152 227 249]\n",
            "   [ 17  92 167 242 249]\n",
            "   [ 32 107 182 249 249]\n",
            "   [ 47 122 197 249 249]\n",
            "   [ 62 137 212 249 249]]\n",
            "\n",
            "  [[  5  80 155 230 249]\n",
            "   [ 20  95 170 245 249]\n",
            "   [ 35 110 185 249 249]\n",
            "   [ 50 125 200 249 249]\n",
            "   [ 65 140 215 249 249]]\n",
            "\n",
            "  [[  8  83 158 233 249]\n",
            "   [ 23  98 173 248 249]\n",
            "   [ 38 113 188 249 249]\n",
            "   [ 53 128 203 249 249]\n",
            "   [ 68 143 218 249 249]]\n",
            "\n",
            "  [[ 11  86 161 236 249]\n",
            "   [ 26 101 176 249 249]\n",
            "   [ 41 116 191 249 249]\n",
            "   [ 56 131 206 249 249]\n",
            "   [ 71 146 221 249 249]]\n",
            "\n",
            "  [[ 14  89 164 239 249]\n",
            "   [ 29 104 179 249 249]\n",
            "   [ 44 119 194 249 249]\n",
            "   [ 59 134 209 249 249]\n",
            "   [ 74 149 224 249 249]]]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([    248292,   91581192,  893666592, 3646635876, 3844124001], dtype=int64)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use vmap to batch generation of plaqs over an array of states\n",
        "@jax.jit\n",
        "def tensor_links_to_plaqs_xy_batched(tensor_links_batched):\n",
        "    return jax.vmap(tensor_links_to_plaqs_xy, in_axes=(0), out_axes=0)(tensor_links_batched)\n",
        "\n",
        "# use vmap to batch generation of plaqs over an array of states\n",
        "@jax.jit\n",
        "def tensor_links_to_plaqs_yz_batched(tensor_links_batched):\n",
        "    return jax.vmap(tensor_links_to_plaqs_yz, in_axes=(0), out_axes=0)(tensor_links_batched)\n",
        "\n",
        "# use vmap to batch generation of plaqs over an array of states\n",
        "@jax.jit\n",
        "def tensor_links_to_plaqs_zx_batched(tensor_links_batched):\n",
        "    return jax.vmap(tensor_links_to_plaqs_zx, in_axes=(0), out_axes=0)(tensor_links_batched)\n",
        "\n",
        "x = hi.random_state(key=jax.random.PRNGKey(0), size=7)\n",
        "tensor_links_to_plaqs_xy_batched(links_to_tensor_batched(x)).shape\n",
        "jnp.expand_dims(tensor_links_to_plaqs_xy_batched(links_to_tensor_batched(x)), axis=1).shape\n",
        "\n",
        "jnp.concatenate([tensor_links_to_plaqs_xy_batched(links_to_tensor_batched(x)),tensor_links_to_plaqs_xy_batched(links_to_tensor_batched(x))], axis=1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx6W7o1r-aNZ",
        "outputId": "43d46f34-83f6-48ab-81f5-3d8e347ba142"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 10, 5, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flax layer to compute plaquettes from link phases\n",
        "\n",
        "Input: (n_batch, 0 or 1, x coord, y coord)\n",
        "Output: (n_batch, channel, x coord, y coord)\n",
        "\n",
        "Input are link phase variables as a tensor, with 0 or 1 labelling whether they are the x or y links associated to a node at (x coord, y coord).\n",
        "\n",
        "In the output, we have a batch of plaq tensors with an extra channel index (= 0) so that we can treat it as a $W_{x,i}$ variable with one channel."
      ],
      "metadata": {
        "id": "JPSH8O7dzRSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A Flax model must be a class subclassing `nn.Module`\n",
        "# The most compact way to define the model is this.\n",
        "# The __call__(self, x) function should take as\n",
        "# input a batch of link variables x.shape = (n_batch, 0 or 1 or 2, x coord, y coord, z coord)\n",
        "# and should return a batch of plaqs of shape (n_batch, channels, x coord, y coord, z coord)\n",
        "class Plaq(nn.Module):\n",
        "\n",
        "    # You can define attributes at the module-level\n",
        "    # with a default. This allows you to easily change\n",
        "    # some hyper-parameter without redefining the whole\n",
        "    # flax module.\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, links):\n",
        "        # compute plaqs from links\n",
        "        plaqs_xy = tensor_links_to_plaqs_xy_batched(links)\n",
        "        plaqs_yz = tensor_links_to_plaqs_yz_batched(links)\n",
        "        plaqs_zx = tensor_links_to_plaqs_zx_batched(links)\n",
        "\n",
        "        # convert to a W_i variable by adding a channel index\n",
        "        plaqs_xy = jnp.expand_dims(plaqs_xy, axis=1)\n",
        "        plaqs_yz = jnp.expand_dims(plaqs_yz, axis=1)\n",
        "        plaqs_zx = jnp.expand_dims(plaqs_zx, axis=1)\n",
        "\n",
        "        # convert to a W_i variable by stacking - the xy, yz or zx plaqs are in the channel index\n",
        "        W_batch_i_x_y_z = jnp.concatenate([plaqs_xy, plaqs_yz, plaqs_zx], axis=1)\n",
        "\n",
        "        # return the W_i variables with an extra channel\n",
        "        return W_batch_i_x_y_z\n",
        "\n",
        "# Create an instance of the model.\n",
        "model_2 = Plaq()\n",
        "\n",
        "# Create the local sampler on the hilbert space\n",
        "#sampler = nk.sampler.MetropolisLocal(hi)\n",
        "\n",
        "# Construct the variational state using the model and the sampler above.\n",
        "# n_samples specifies how many samples should be used to compute expectation\n",
        "# values.\n",
        "#vstate = nk.vqs.MCState(sampler, model, n_samples=1000)\n",
        "\n",
        "#vstate.n_parameters\n",
        "\n",
        "x = hi.random_state(key=jax.random.PRNGKey(0), size=2)\n",
        "\n",
        "x = model_1.apply(params_1, x)\n",
        "\n",
        "print(x.shape)\n",
        "\n",
        "key1, key2 = random.split(random.PRNGKey(0))\n",
        "params_2 = model_2.init(key1, x) # Initialization call\n",
        "#jax.tree_util.tree_map(lambda x: x.shape, params) # Checking output shapes\n",
        "\n",
        "print(x)\n",
        "print(model_2.apply(params_2, x))\n",
        "print(model_2.apply(params_2, x).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmXnjAgazV9b",
        "outputId": "10a8ebc5-4cad-448c-b788-1b4badfbbd13"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 3, 5, 5, 5)\n",
            "[[[[[ 1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]]\n",
            "\n",
            "   [[-4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]]]\n",
            "\n",
            "\n",
            "  [[[ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[ 1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]]]\n",
            "\n",
            "\n",
            "  [[[-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[ 1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08+1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]]]]\n",
            "\n",
            "\n",
            "\n",
            " [[[[-4.3711388e-08+1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[ 1.1924881e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]]]\n",
            "\n",
            "\n",
            "  [[[ 1.1924881e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[ 1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]]\n",
            "\n",
            "   [[ 1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]]]\n",
            "\n",
            "\n",
            "  [[[-4.3711388e-08-1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08+1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]]\n",
            "\n",
            "   [[-4.3711388e-08+1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[ 1.1924881e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [ 1.1924881e-08-1.j  1.1924881e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j  1.1924881e-08-1.j]]\n",
            "\n",
            "   [[-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j  1.1924881e-08-1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08+1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08+1.j  1.1924881e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]]\n",
            "\n",
            "   [[-4.3711388e-08+1.j -4.3711388e-08-1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j -4.3711388e-08+1.j\n",
            "      1.1924881e-08-1.j  1.1924881e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08-1.j  1.1924881e-08-1.j\n",
            "      1.1924881e-08-1.j -4.3711388e-08-1.j]\n",
            "    [-4.3711388e-08-1.j -4.3711388e-08+1.j  1.1924881e-08-1.j\n",
            "     -4.3711388e-08+1.j  1.1924881e-08-1.j]\n",
            "    [ 1.1924881e-08-1.j -4.3711388e-08+1.j -4.3711388e-08-1.j\n",
            "     -4.3711388e-08-1.j -4.3711388e-08+1.j]]]]]\n",
            "[[[[[ 1.-5.5636267e-08j -1.+1.4305905e-07j  1.+5.5636271e-08j\n",
            "      1.+0.0000000e+00j  1.+0.0000000e+00j]\n",
            "    [-1.+8.7422777e-08j  1.+0.0000000e+00j  1.-5.5636271e-08j\n",
            "      1.+0.0000000e+00j  1.+0.0000000e+00j]\n",
            "    [ 1.+5.5636271e-08j -1.+3.1786509e-08j  1.+0.0000000e+00j\n",
            "      1.+0.0000000e+00j  1.-6.3573012e-08j]\n",
            "    [-1.+8.7422777e-08j -1.-1.4305905e-07j -1.-2.3849761e-08j\n",
            "      1.+1.1920928e-07j  1.+6.3573012e-08j]\n",
            "    [-1.-8.7422777e-08j  1.+0.0000000e+00j -1.-3.1786506e-08j\n",
            "     -1.+8.7422777e-08j  1.+5.5636267e-08j]]\n",
            "\n",
            "   [[-1.-1.4305905e-07j  1.+0.0000000e+00j  1.+5.5636271e-08j\n",
            "      1.+0.0000000e+00j  1.+5.5636271e-08j]\n",
            "    [-1.-3.1786506e-08j  1.+0.0000000e+00j  1.-5.5636271e-08j\n",
            "     -1.+3.1786506e-08j  1.+0.0000000e+00j]\n",
            "    [ 1.-6.3573012e-08j  1.+6.3573012e-08j  1.+5.5636267e-08j\n",
            "      1.+0.0000000e+00j  1.-1.1127254e-07j]\n",
            "    [ 1.-5.5636271e-08j  1.-5.5636267e-08j  1.+0.0000000e+00j\n",
            "     -1.+8.7422777e-08j -1.+3.1786506e-08j]\n",
            "    [ 1.+0.0000000e+00j -1.-2.3849761e-08j  1.-1.7484555e-07j\n",
            "     -1.-3.1786506e-08j -1.+8.7422777e-08j]]\n",
            "\n",
            "   [[ 1.+0.0000000e+00j -1.-1.4305905e-07j -1.+8.7422777e-08j\n",
            "     -1.-3.1786506e-08j  1.+1.1920928e-07j]\n",
            "    [ 1.-1.7484555e-07j -1.-3.1786506e-08j -1.+8.7422777e-08j\n",
            "      1.+1.1920928e-07j  1.+0.0000000e+00j]\n",
            "    [ 1.+0.0000000e+00j -1.+3.1786506e-08j -1.-3.1786506e-08j\n",
            "      1.+0.0000000e+00j -1.-3.1786506e-08j]\n",
            "    [ 1.+1.1920928e-07j  1.+5.5636271e-08j -1.-3.1786509e-08j\n",
            "      1.+0.0000000e+00j -1.+3.1786506e-08j]\n",
            "    [ 1.+0.0000000e+00j -1.-3.1786509e-08j  1.+0.0000000e+00j\n",
            "     -1.+3.1786506e-08j  1.+0.0000000e+00j]]\n",
            "\n",
            "   [[-1.-3.1786509e-08j -1.+3.1786506e-08j -1.-8.7422777e-08j\n",
            "      1.-1.1920928e-07j  1.+0.0000000e+00j]\n",
            "    [-1.-8.7422777e-08j  1.+0.0000000e+00j  1.+0.0000000e+00j\n",
            "      1.+0.0000000e+00j  1.+0.0000000e+00j]\n",
            "    [ 1.+0.0000000e+00j  1.-5.5636271e-08j  1.+0.0000000e+00j\n",
            "      1.+0.0000000e+00j  1.+0.0000000e+00j]\n",
            "    [ 1.+0.0000000e+00j  1.+5.5636267e-08j  1.-5.5636267e-08j\n",
            "     -1.-3.1786509e-08j -1.-1.4305905e-07j]\n",
            "    [ 1.+5.5636271e-08j -1.+2.3849761e-08j -1.-1.4305905e-07j\n",
            "      1.+0.0000000e+00j  1.-5.5636271e-08j]]\n",
            "\n",
            "   [[ 1.-5.5636267e-08j  1.+0.0000000e+00j -1.-3.1786506e-08j\n",
            "      1.+5.5636267e-08j -1.-3.1786506e-08j]\n",
            "    [ 1.+5.5636271e-08j  1.-5.5636271e-08j  1.+5.5636271e-08j\n",
            "     -1.+3.1786509e-08j -1.+1.4305905e-07j]\n",
            "    [ 1.-5.5636271e-08j  1.-6.3573012e-08j  1.+0.0000000e+00j\n",
            "     -1.+3.1786506e-08j -1.-3.1786506e-08j]\n",
            "    [ 1.+0.0000000e+00j  1.-5.5636271e-08j -1.-3.1786509e-08j\n",
            "      1.+0.0000000e+00j  1.-6.3573012e-08j]\n",
            "    [-1.+3.1786506e-08j  1.+0.0000000e+00j  1.-1.1920928e-07j\n",
            "     -1.-3.1786506e-08j  1.+5.5636271e-08j]]]\n",
            "\n",
            "\n",
            "  [[[-1.+3.1786506e-08j  1.+0.0000000e+00j -1.-8.7422777e-08j\n",
            "     -1.+3.1786506e-08j -1.+2.3849761e-08j]\n",
            "    [-1.-8.7422777e-08j -1.+3.1786506e-08j -1.+2.3849761e-08j\n",
            "      1.+1.1127254e-07j -1.+3.1786506e-08j]\n",
            "    [-1.-8.7422777e-08j  1.-5.5636267e-08j  1.+0.0000000e+00j\n",
            "     -1.+8.7422777e-08j -1.-3.1786506e-08j]\n",
            "    [ 1.+5.5636267e-08j -1.+3.1786506e-08j -1.-8.7422777e-08j\n",
            "      1.+5.5636267e-08j -1.+3.1786509e-08j]\n",
            "    [ 1.-5.5636271e-08j  1.-5.5636271e-08j -1.+1.4305905e-07j\n",
            "     -1.+2.3849761e-08j  1.+5.5636267e-08j]]\n",
            "\n",
            "   [[ 1.+5.5636271e-08j  1.+0.0000000e+00j  1.-5.5636271e-08j\n",
            "     -1.+8.7422777e-08j -1.-1.4305905e-07j]\n",
            "    [ 1.-5.5636271e-08j  1.-1.7484555e-07j  1.+0.0000000e+00j\n",
            "     -1.-3.1786506e-08j -1.-8.7422777e-08j]\n",
            "    [-1.-3.1786506e-08j  1.+0.0000000e+00j  1.+5.5636267e-08j\n",
            "      1.+5.5636267e-08j  1.-6.3573012e-08j]\n",
            "    [ 1.+5.5636267e-08j  1.+5.5636267e-08j -1.+8.7422777e-08j\n",
            "     -1.-3.1786506e-08j -1.-3.1786509e-08j]\n",
            "    [ 1.+0.0000000e+00j -1.+1.4305905e-07j  1.+1.1920928e-07j\n",
            "     -1.+3.1786509e-08j  1.-5.5636267e-08j]]\n",
            "\n",
            "   [[ 1.+0.0000000e+00j  1.-5.5636267e-08j -1.+8.7422777e-08j\n",
            "      1.+5.5636267e-08j  1.+0.0000000e+00j]\n",
            "    [-1.-1.4305905e-07j -1.+1.4305905e-07j  1.+1.1920928e-07j\n",
            "     -1.-3.1786509e-08j  1.-6.3573012e-08j]\n",
            "    [-1.+3.1786509e-08j -1.-8.7422777e-08j  1.+0.0000000e+00j\n",
            "     -1.+3.1786506e-08j  1.-5.5636267e-08j]\n",
            "    [-1.-3.1786506e-08j  1.-5.5636267e-08j  1.+5.5636271e-08j\n",
            "      1.+0.0000000e+00j  1.-5.5636271e-08j]\n",
            "    [-1.+3.1786509e-08j  1.+5.5636267e-08j -1.+8.7422777e-08j\n",
            "     -1.-3.1786506e-08j -1.-8.7422777e-08j]]\n",
            "\n",
            "   [[ 1.-1.1920928e-07j  1.+5.5636271e-08j  1.-5.5636271e-08j\n",
            "     -1.+8.7422777e-08j -1.-3.1786509e-08j]\n",
            "    [-1.+3.1786506e-08j -1.-3.1786506e-08j  1.-1.1920928e-07j\n",
            "      1.+1.1920928e-07j  1.+5.5636267e-08j]\n",
            "    [ 1.+0.0000000e+00j -1.-8.7422777e-08j -1.-3.1786509e-08j\n",
            "      1.-6.3573012e-08j -1.-3.1786509e-08j]\n",
            "    [ 1.-5.5636271e-08j -1.+8.7422777e-08j  1.+0.0000000e+00j\n",
            "      1.+5.5636267e-08j  1.-5.5636271e-08j]\n",
            "    [-1.-3.1786506e-08j -1.-1.4305905e-07j -1.+8.7422777e-08j\n",
            "      1.+6.3573012e-08j -1.-2.3849761e-08j]]\n",
            "\n",
            "   [[-1.+3.1786506e-08j -1.-3.1786506e-08j  1.+0.0000000e+00j\n",
            "     -1.+1.4305905e-07j -1.+8.7422777e-08j]\n",
            "    [-1.-1.4305905e-07j  1.-1.1920928e-07j  1.+1.1920928e-07j\n",
            "     -1.-8.7422777e-08j -1.+3.1786506e-08j]\n",
            "    [-1.-3.1786506e-08j -1.-3.1786506e-08j  1.-1.7484555e-07j\n",
            "     -1.+3.1786506e-08j  1.+5.5636271e-08j]\n",
            "    [ 1.+0.0000000e+00j -1.-8.7422777e-08j  1.+0.0000000e+00j\n",
            "      1.+0.0000000e+00j  1.+6.3573012e-08j]\n",
            "    [-1.+8.7422777e-08j -1.+3.1786506e-08j -1.-8.7422777e-08j\n",
            "      1.+0.0000000e+00j  1.+0.0000000e+00j]]]\n",
            "\n",
            "\n",
            "  [[[ 1.-5.5636271e-08j  1.+5.5636271e-08j -1.+8.7422777e-08j\n",
            "      1.-1.1127254e-07j  1.+1.1127254e-07j]\n",
            "    [ 1.-5.5636267e-08j -1.+1.4305905e-07j  1.+1.1127254e-07j\n",
            "      1.-5.5636271e-08j  1.+0.0000000e+00j]\n",
            "    [ 1.+0.0000000e+00j  1.+5.5636267e-08j -1.-3.1786506e-08j\n",
            "     -1.-2.3849761e-08j -1.+3.1786509e-08j]\n",
            "    [-1.-1.4305905e-07j -1.+3.1786506e-08j -1.+2.3849761e-08j\n",
            "      1.-5.5636271e-08j  1.-5.5636271e-08j]\n",
            "    [-1.+8.7422777e-08j  1.+0.0000000e+00j  1.+5.5636271e-08j\n",
            "     -1.-2.3849761e-08j -1.-3.1786509e-08j]]\n",
            "\n",
            "   [[ 1.-5.5636271e-08j  1.-5.5636271e-08j  1.+0.0000000e+00j\n",
            "      1.+5.5636271e-08j -1.+8.7422777e-08j]\n",
            "    [-1.-1.4305905e-07j  1.-5.5636271e-08j -1.-8.7422777e-08j\n",
            "     -1.+1.4305905e-07j -1.+3.1786506e-08j]\n",
            "    [-1.+2.3849761e-08j -1.+3.1786506e-08j  1.-5.5636271e-08j\n",
            "      1.-1.7484555e-07j -1.-8.7422777e-08j]\n",
            "    [-1.+8.7422777e-08j  1.-1.1127254e-07j  1.+5.5636271e-08j\n",
            "     -1.-2.3849761e-08j -1.-3.1786509e-08j]\n",
            "    [ 1.-6.3573012e-08j  1.-5.5636267e-08j  1.+0.0000000e+00j\n",
            "      1.+0.0000000e+00j -1.-1.4305905e-07j]]\n",
            "\n",
            "   [[-1.-2.3849761e-08j -1.+3.1786509e-08j  1.+6.3573012e-08j\n",
            "     -1.+8.7422777e-08j  1.-5.5636271e-08j]\n",
            "    [ 1.+0.0000000e+00j -1.-8.7422777e-08j -1.+8.7422777e-08j\n",
            "     -1.+3.1786506e-08j -1.-3.1786506e-08j]\n",
            "    [-1.+3.1786509e-08j -1.-3.1786506e-08j  1.-5.5636271e-08j\n",
            "      1.+0.0000000e+00j -1.-8.7422777e-08j]\n",
            "    [-1.+3.1786506e-08j -1.+3.1786506e-08j  1.-5.5636271e-08j\n",
            "      1.+0.0000000e+00j -1.-3.1786509e-08j]\n",
            "    [ 1.+1.1920928e-07j -1.-2.3849761e-08j -1.-3.1786509e-08j\n",
            "     -1.+2.3849761e-08j  1.-1.1920928e-07j]]\n",
            "\n",
            "   [[ 1.+5.5636271e-08j -1.+2.3849761e-08j -1.-2.3849761e-08j\n",
            "     -1.-3.1786506e-08j -1.+3.1786506e-08j]\n",
            "    [-1.-3.1786506e-08j  1.-1.1920928e-07j  1.+1.7484555e-07j\n",
            "     -1.+3.1786506e-08j  1.+5.5636267e-08j]\n",
            "    [ 1.-5.5636267e-08j -1.-3.1786506e-08j  1.-6.3573012e-08j\n",
            "      1.+0.0000000e+00j  1.+5.5636267e-08j]\n",
            "    [-1.+3.1786506e-08j -1.-3.1786506e-08j -1.-1.4305905e-07j\n",
            "     -1.+3.1786509e-08j -1.-3.1786509e-08j]\n",
            "    [-1.+1.4305905e-07j -1.+3.1786506e-08j  1.+5.5636267e-08j\n",
            "     -1.+8.7422777e-08j  1.+5.5636271e-08j]]\n",
            "\n",
            "   [[ 1.+0.0000000e+00j -1.-1.4305905e-07j  1.+5.5636271e-08j\n",
            "     -1.-3.1786506e-08j -1.-3.1786506e-08j]\n",
            "    [ 1.-5.5636271e-08j -1.-1.4305905e-07j  1.-5.5636267e-08j\n",
            "      1.-5.5636271e-08j  1.+5.5636271e-08j]\n",
            "    [ 1.+1.1127254e-07j  1.-5.5636267e-08j  1.+1.7484555e-07j\n",
            "     -1.-3.1786506e-08j -1.+1.4305905e-07j]\n",
            "    [ 1.+6.3573012e-08j -1.+3.1786506e-08j -1.-3.1786506e-08j\n",
            "     -1.-2.3849761e-08j -1.+3.1786509e-08j]\n",
            "    [ 1.+6.3573012e-08j  1.+0.0000000e+00j -1.+2.3849761e-08j\n",
            "     -1.-3.1786506e-08j  1.+0.0000000e+00j]]]]\n",
            "\n",
            "\n",
            "\n",
            " [[[[-1.-3.1786509e-08j  1.-1.1920928e-07j -1.+8.7422777e-08j\n",
            "     -1.+3.1786506e-08j -1.+8.7422777e-08j]\n",
            "    [-1.-2.3849761e-08j  1.+1.1920928e-07j  1.-5.5636271e-08j\n",
            "      1.+0.0000000e+00j -1.+2.3849761e-08j]\n",
            "    [-1.-1.4305905e-07j  1.-5.5636267e-08j  1.+6.3573012e-08j\n",
            "     -1.+2.3849761e-08j  1.+0.0000000e+00j]\n",
            "    [-1.+8.7422777e-08j  1.+5.5636267e-08j  1.+5.5636271e-08j\n",
            "     -1.+3.1786509e-08j -1.-3.1786506e-08j]\n",
            "    [-1.+8.7422777e-08j -1.+2.3849761e-08j -1.-3.1786506e-08j\n",
            "      1.+6.3573012e-08j -1.-3.1786509e-08j]]\n",
            "\n",
            "   [[-1.+3.1786509e-08j -1.-8.7422777e-08j  1.+0.0000000e+00j\n",
            "     -1.-8.7422777e-08j  1.+1.7484555e-07j]\n",
            "    [-1.-3.1786506e-08j  1.+0.0000000e+00j -1.-8.7422777e-08j\n",
            "     -1.+3.1786506e-08j  1.+0.0000000e+00j]\n",
            "    [ 1.-1.1127254e-07j  1.-5.5636271e-08j -1.+3.1786506e-08j\n",
            "      1.-5.5636271e-08j  1.-6.3573012e-08j]\n",
            "    [ 1.+5.5636267e-08j  1.-1.1127254e-07j -1.+8.7422777e-08j\n",
            "      1.+0.0000000e+00j  1.+1.1920928e-07j]\n",
            "    [ 1.-5.5636267e-08j  1.-1.1920928e-07j -1.+8.7422777e-08j\n",
            "     -1.+8.7422777e-08j  1.-1.1920928e-07j]]\n",
            "\n",
            "   [[-1.+1.4305905e-07j  1.+5.5636271e-08j  1.+5.5636267e-08j\n",
            "      1.+0.0000000e+00j -1.+3.1786509e-08j]\n",
            "    [-1.-8.7422777e-08j -1.+8.7422777e-08j  1.+0.0000000e+00j\n",
            "     -1.-8.7422777e-08j  1.+5.5636267e-08j]\n",
            "    [-1.-8.7422777e-08j  1.+1.1127254e-07j -1.-3.1786509e-08j\n",
            "      1.+0.0000000e+00j  1.-5.5636267e-08j]\n",
            "    [ 1.-5.5636267e-08j  1.+0.0000000e+00j  1.+0.0000000e+00j\n",
            "     -1.-8.7422777e-08j -1.+8.7422777e-08j]\n",
            "    [ 1.+1.1127254e-07j -1.-3.1786506e-08j -1.+8.7422777e-08j\n",
            "      1.+0.0000000e+00j  1.+0.0000000e+00j]]\n",
            "\n",
            "   [[-1.-8.7422777e-08j  1.+0.0000000e+00j -1.-8.7422777e-08j\n",
            "     -1.-3.1786509e-08j -1.+2.3849761e-08j]\n",
            "    [-1.+8.7422777e-08j  1.+0.0000000e+00j -1.+8.7422777e-08j\n",
            "      1.+0.0000000e+00j -1.+8.7422777e-08j]\n",
            "    [-1.+8.7422777e-08j  1.-5.5636271e-08j  1.+5.5636271e-08j\n",
            "      1.+1.1127254e-07j  1.+1.1920928e-07j]\n",
            "    [ 1.+0.0000000e+00j -1.+3.1786506e-08j  1.+0.0000000e+00j\n",
            "      1.-5.5636271e-08j -1.-3.1786506e-08j]\n",
            "    [-1.-3.1786506e-08j  1.+0.0000000e+00j  1.+0.0000000e+00j\n",
            "      1.+0.0000000e+00j  1.+1.1127254e-07j]]\n",
            "\n",
            "   [[ 1.+5.5636267e-08j  1.+5.5636271e-08j  1.+0.0000000e+00j\n",
            "      1.+0.0000000e+00j -1.-2.3849761e-08j]\n",
            "    [ 1.+0.0000000e+00j  1.+0.0000000e+00j  1.+5.5636267e-08j\n",
            "     -1.+8.7422777e-08j  1.+0.0000000e+00j]\n",
            "    [ 1.+5.5636271e-08j -1.-1.4305905e-07j  1.+5.5636267e-08j\n",
            "      1.+0.0000000e+00j -1.+3.1786509e-08j]\n",
            "    [ 1.-5.5636271e-08j -1.+8.7422777e-08j  1.+0.0000000e+00j\n",
            "     -1.+8.7422777e-08j  1.-1.1920928e-07j]\n",
            "    [ 1.+0.0000000e+00j -1.-8.7422777e-08j  1.-5.5636271e-08j\n",
            "     -1.-2.3849761e-08j -1.-3.1786509e-08j]]]\n",
            "\n",
            "\n",
            "  [[[ 1.+5.5636271e-08j -1.-3.1786509e-08j  1.+5.5636271e-08j\n",
            "     -1.-3.1786506e-08j  1.-5.5636267e-08j]\n",
            "    [-1.+1.4305905e-07j  1.-5.5636267e-08j -1.+3.1786506e-08j\n",
            "      1.-5.5636271e-08j  1.+1.1127254e-07j]\n",
            "    [-1.-3.1786506e-08j  1.+0.0000000e+00j -1.-8.7422777e-08j\n",
            "     -1.-8.7422777e-08j  1.+5.5636267e-08j]\n",
            "    [ 1.-5.5636271e-08j -1.-1.4305905e-07j  1.-5.5636271e-08j\n",
            "     -1.-2.3849761e-08j  1.-5.5636271e-08j]\n",
            "    [ 1.+0.0000000e+00j  1.-6.3573012e-08j  1.-5.5636271e-08j\n",
            "      1.-5.5636267e-08j -1.+3.1786509e-08j]]\n",
            "\n",
            "   [[-1.+3.1786506e-08j  1.-5.5636271e-08j  1.+0.0000000e+00j\n",
            "     -1.-3.1786506e-08j  1.-5.5636271e-08j]\n",
            "    [-1.+3.1786506e-08j -1.-8.7422777e-08j -1.+1.4305905e-07j\n",
            "     -1.-8.7422777e-08j -1.+8.7422777e-08j]\n",
            "    [-1.-8.7422777e-08j -1.+3.1786506e-08j  1.+1.7484555e-07j\n",
            "      1.-1.1920928e-07j  1.+6.3573012e-08j]\n",
            "    [-1.+8.7422777e-08j -1.+3.1786506e-08j  1.+0.0000000e+00j\n",
            "      1.+5.5636267e-08j -1.+3.1786506e-08j]\n",
            "    [ 1.+0.0000000e+00j  1.+5.5636271e-08j  1.+0.0000000e+00j\n",
            "      1.+0.0000000e+00j  1.+6.3573012e-08j]]\n",
            "\n",
            "   [[-1.-8.7422777e-08j  1.+5.5636271e-08j  1.-5.5636267e-08j\n",
            "      1.+5.5636271e-08j -1.-3.1786506e-08j]\n",
            "    [-1.+8.7422777e-08j -1.-3.1786506e-08j  1.+0.0000000e+00j\n",
            "     -1.+1.4305905e-07j -1.-1.4305905e-07j]\n",
            "    [-1.+3.1786506e-08j  1.+0.0000000e+00j -1.-8.7422777e-08j\n",
            "     -1.-3.1786506e-08j -1.+3.1786506e-08j]\n",
            "    [-1.-8.7422777e-08j -1.-3.1786506e-08j -1.+8.7422777e-08j\n",
            "      1.-1.7484555e-07j -1.-8.7422777e-08j]\n",
            "    [-1.+3.1786506e-08j  1.-1.7484555e-07j  1.+5.5636271e-08j\n",
            "     -1.-8.7422777e-08j  1.-5.5636271e-08j]]\n",
            "\n",
            "   [[ 1.+0.0000000e+00j  1.+0.0000000e+00j -1.+3.1786509e-08j\n",
            "      1.+0.0000000e+00j -1.-8.7422777e-08j]\n",
            "    [ 1.-5.5636271e-08j -1.-8.7422777e-08j -1.+8.7422777e-08j\n",
            "      1.-5.5636271e-08j -1.+3.1786506e-08j]\n",
            "    [ 1.+1.1920928e-07j -1.+3.1786506e-08j -1.-8.7422777e-08j\n",
            "      1.+0.0000000e+00j -1.-2.3849761e-08j]\n",
            "    [ 1.+5.5636271e-08j -1.+3.1786506e-08j -1.+1.4305905e-07j\n",
            "     -1.-3.1786506e-08j -1.+2.3849761e-08j]\n",
            "    [ 1.-1.1920928e-07j -1.-3.1786506e-08j  1.+0.0000000e+00j\n",
            "      1.+1.7484555e-07j -1.+8.7422777e-08j]]\n",
            "\n",
            "   [[-1.+8.7422777e-08j  1.-5.5636271e-08j  1.+5.5636271e-08j\n",
            "      1.+5.5636271e-08j  1.+5.5636271e-08j]\n",
            "    [ 1.-5.5636271e-08j  1.+5.5636271e-08j  1.-1.1920928e-07j\n",
            "     -1.-8.7422777e-08j  1.-5.5636271e-08j]\n",
            "    [ 1.+0.0000000e+00j -1.-3.1786506e-08j  1.+0.0000000e+00j\n",
            "      1.+0.0000000e+00j -1.-1.4305905e-07j]\n",
            "    [ 1.+5.5636267e-08j  1.+5.5636271e-08j -1.+1.4305905e-07j\n",
            "     -1.+8.7422777e-08j  1.+6.3573012e-08j]\n",
            "    [ 1.+1.1920928e-07j  1.-1.7484555e-07j  1.+0.0000000e+00j\n",
            "     -1.-3.1786506e-08j -1.+3.1786506e-08j]]]\n",
            "\n",
            "\n",
            "  [[[ 1.-1.1920928e-07j  1.+0.0000000e+00j  1.-5.5636267e-08j\n",
            "      1.-5.5636267e-08j  1.+0.0000000e+00j]\n",
            "    [ 1.+1.1920928e-07j  1.+5.5636271e-08j  1.-5.5636271e-08j\n",
            "      1.+0.0000000e+00j  1.-1.1920928e-07j]\n",
            "    [-1.+8.7422777e-08j -1.-8.7422777e-08j  1.+0.0000000e+00j\n",
            "      1.-1.1920928e-07j -1.-3.1786509e-08j]\n",
            "    [ 1.+5.5636271e-08j  1.+0.0000000e+00j  1.+0.0000000e+00j\n",
            "      1.+6.3573012e-08j  1.-1.1920928e-07j]\n",
            "    [ 1.-5.5636271e-08j  1.+1.7484555e-07j -1.-3.1786506e-08j\n",
            "     -1.+3.1786509e-08j -1.+2.3849761e-08j]]\n",
            "\n",
            "   [[ 1.+6.3573012e-08j  1.+5.5636271e-08j  1.+0.0000000e+00j\n",
            "      1.+5.5636271e-08j  1.+5.5636271e-08j]\n",
            "    [ 1.-1.7484555e-07j -1.-3.1786506e-08j -1.+3.1786509e-08j\n",
            "      1.-5.5636271e-08j  1.+1.7484555e-07j]\n",
            "    [-1.+8.7422777e-08j  1.+0.0000000e+00j  1.-5.5636271e-08j\n",
            "     -1.-1.4305905e-07j -1.+8.7422777e-08j]\n",
            "    [-1.+2.3849761e-08j  1.-5.5636271e-08j  1.+5.5636271e-08j\n",
            "      1.+0.0000000e+00j  1.+5.5636271e-08j]\n",
            "    [-1.+3.1786509e-08j -1.+1.4305905e-07j  1.+5.5636271e-08j\n",
            "      1.+1.1127254e-07j  1.+0.0000000e+00j]]\n",
            "\n",
            "   [[ 1.+1.1127254e-07j  1.+0.0000000e+00j -1.+8.7422777e-08j\n",
            "     -1.+3.1786506e-08j  1.-1.1127254e-07j]\n",
            "    [ 1.+0.0000000e+00j  1.+5.5636267e-08j  1.-5.5636267e-08j\n",
            "      1.+5.5636271e-08j  1.-5.5636271e-08j]\n",
            "    [-1.-1.4305905e-07j -1.+8.7422777e-08j  1.-5.5636267e-08j\n",
            "      1.+0.0000000e+00j -1.-8.7422777e-08j]\n",
            "    [-1.+3.1786506e-08j -1.-2.3849761e-08j -1.+2.3849761e-08j\n",
            "     -1.-8.7422777e-08j  1.-1.1127254e-07j]\n",
            "    [ 1.-5.5636271e-08j -1.-8.7422777e-08j  1.-5.5636271e-08j\n",
            "      1.+5.5636271e-08j -1.+3.1786509e-08j]]\n",
            "\n",
            "   [[ 1.-1.7484555e-07j -1.-8.7422777e-08j  1.+5.5636271e-08j\n",
            "     -1.-3.1786506e-08j  1.+5.5636271e-08j]\n",
            "    [ 1.+0.0000000e+00j  1.+5.5636271e-08j -1.-2.3849761e-08j\n",
            "     -1.-3.1786509e-08j -1.+2.3849761e-08j]\n",
            "    [-1.+8.7422777e-08j  1.+1.7484555e-07j -1.+3.1786509e-08j\n",
            "     -1.+2.3849761e-08j  1.+0.0000000e+00j]\n",
            "    [ 1.+0.0000000e+00j  1.+0.0000000e+00j  1.+0.0000000e+00j\n",
            "     -1.+3.1786506e-08j -1.-8.7422777e-08j]\n",
            "    [-1.-3.1786506e-08j  1.-1.1920928e-07j  1.+5.5636271e-08j\n",
            "      1.+0.0000000e+00j -1.-3.1786506e-08j]]\n",
            "\n",
            "   [[-1.-8.7422777e-08j  1.-5.5636267e-08j  1.-5.5636271e-08j\n",
            "      1.+5.5636271e-08j -1.-3.1786509e-08j]\n",
            "    [ 1.-5.5636271e-08j -1.+8.7422777e-08j  1.-5.5636271e-08j\n",
            "      1.+5.5636271e-08j  1.+1.1127254e-07j]\n",
            "    [-1.-3.1786506e-08j -1.+3.1786506e-08j  1.+0.0000000e+00j\n",
            "      1.+1.1127254e-07j  1.-5.5636267e-08j]\n",
            "    [-1.+8.7422777e-08j -1.-8.7422777e-08j -1.+3.1786506e-08j\n",
            "      1.+5.5636271e-08j  1.-5.5636267e-08j]\n",
            "    [ 1.+5.5636271e-08j -1.+8.7422777e-08j -1.+3.1786506e-08j\n",
            "     -1.+2.3849761e-08j  1.+0.0000000e+00j]]]]]\n",
            "(2, 3, 5, 5, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Functions for shifting plaquette variables"
      ],
      "metadata": {
        "id": "wsbfgo12Dn7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function which takes in a tensor of plaquette variables and shifts them by a specified amount in x, y or z direction.\n",
        "# In practice, this means it takes in W_x and returns W_(x + mu)\n",
        "@jax.jit\n",
        "def shift_plaqs(plaqs_tensor, mu_x, mu_y, mu_z):\n",
        "    return jnp.roll(plaqs_tensor, (-mu_x, -mu_y, -mu_z), axis=(0,1,2))"
      ],
      "metadata": {
        "id": "oJUuRLtbDs4r"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# only works for one *positive* unit of transport at the moment, as you need to multiply all the link variables!\n",
        "# and the negative shifts are actually a little different!\n",
        "@jax.jit\n",
        "def transport_x(plaqs_tensor, links_tensor, mu_x):\n",
        "    plaqs = shift_plaqs(plaqs_tensor, mu_x, 0, 0)\n",
        "    return jnp.multiply(jnp.multiply(links_tensor[0], plaqs), jnp.conj(links_tensor[0]))\n",
        "\n",
        "# only works for one *positive* unit of transport at the moment, as you need to multiply all the link variables!\n",
        "# and the negative shifts are actually a little different!\n",
        "@jax.jit\n",
        "def transport_y(plaqs_tensor, links_tensor, mu_y):\n",
        "    plaqs = shift_plaqs(plaqs_tensor, 0, mu_y, 0)\n",
        "    return jnp.multiply(jnp.multiply(links_tensor[1], plaqs), jnp.conj(links_tensor[1]))\n",
        "\n",
        "# only works for one *positive* unit of transport at the moment, as you need to multiply all the link variables!\n",
        "# and the negative shifts are actually a little different!\n",
        "@jax.jit\n",
        "def transport_z(plaqs_tensor, links_tensor, mu_z):\n",
        "    plaqs = shift_plaqs(plaqs_tensor, 0, 0, mu_z)\n",
        "    return jnp.multiply(jnp.multiply(links_tensor[2], plaqs), jnp.conj(links_tensor[2]))"
      ],
      "metadata": {
        "id": "ufzag0lyMKCd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def transport_x_batched(plaqs_tensor_batch, links_tensor_batch, mu_x):\n",
        "    return jax.vmap(transport_x, in_axes=(0,0,None), out_axes=0)(plaqs_tensor_batch, links_tensor_batch, mu_x)\n",
        "\n",
        "@jax.jit\n",
        "def transport_y_batched(plaqs_tensor_batch, links_tensor_batch, mu_y):\n",
        "    return jax.vmap(transport_y, in_axes=(0,0,None), out_axes=0)(plaqs_tensor_batch, links_tensor_batch, mu_y)\n",
        "\n",
        "@jax.jit\n",
        "def transport_z_batched(plaqs_tensor_batch, links_tensor_batch, mu_z):\n",
        "    return jax.vmap(transport_z, in_axes=(0,0,None), out_axes=0)(plaqs_tensor_batch, links_tensor_batch, mu_z)"
      ],
      "metadata": {
        "id": "5ZTi-v-nDIWj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def transport_x_batched_channel(W_tensor_batch_channel, links_tensor_batch, mu_x):\n",
        "    return jax.vmap(transport_x_batched, in_axes=(1,None,None), out_axes=1)(W_tensor_batch_channel, links_tensor_batch, mu_x)\n",
        "\n",
        "@jax.jit\n",
        "def transport_y_batched_channel(W_tensor_batch_channel, links_tensor_batch, mu_y):\n",
        "    return jax.vmap(transport_y_batched, in_axes=(1,None,None), out_axes=1)(W_tensor_batch_channel, links_tensor_batch, mu_y)\n",
        "\n",
        "@jax.jit\n",
        "def transport_z_batched_channel(W_tensor_batch_channel, links_tensor_batch, mu_z):\n",
        "    return jax.vmap(transport_z_batched, in_axes=(1,None,None), out_axes=1)(W_tensor_batch_channel, links_tensor_batch, mu_z)"
      ],
      "metadata": {
        "id": "Tg0P42v443FM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. New LConvBilin layer"
      ],
      "metadata": {
        "id": "bJCBAaPu44MJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flax layer to compute LConvBilin layer from link phases $U_{x,\\mu}$ and locally transforming variables $W_{x,i}$ where $i$ labels the channel.\n",
        "\n",
        "Input: (n_batch, 0 or 1, x coord, y coord) and (n_batch, i, x coord, y coord)\n",
        "Output: (n_batch, j, x coord, y coord)\n",
        "\n",
        "Input are link phase variables as a tensor, with 0 or 1 labelling whether they are the x or y links associated to a node at (x coord, y coord), and the $W_{x,i}$ variables with $i=0,\\dots,N_{\\text{in}}-1$.\n",
        "\n",
        "In the output, we have a batch of locally transforming variables $W_{x,j}$ where $j=0,\\dots,N_{\\text{out}}-1$."
      ],
      "metadata": {
        "id": "CMqm9IsZw2lT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A Flax model must be a class subclassing `nn.Module`\n",
        "# The most compact way to define the model is this.\n",
        "# The __call__(self, x) function should take as\n",
        "# input a batch of states x.shape = (n_samples, spin_states)\n",
        "# and should return (n_samples, phases)\n",
        "class LConvBilin(nn.Module):\n",
        "\n",
        "    # You can define attributes at the module-level\n",
        "    # with a default. This allows you to easily change\n",
        "    # some hyper-parameter without redefining the whole\n",
        "    # flax module.\n",
        "    N_out: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, links, plaqs_i):\n",
        "\n",
        "        # input is batch of plaq variables with extra i index for one channel\n",
        "        W_batch_i_x_y_z = plaqs_i\n",
        "\n",
        "        # consider only positive shifts along lattice axis, as in Vienna group sup. mat.\n",
        "        W_batch_i_x_p_y_z = transport_x_batched_channel(W_batch_i_x_y_z, links, 1)\n",
        "        # W_batch_i_x_m_y = transport_x_batched_channel(W_batch_i_x_y, links, -1)\n",
        "        W_batch_i_x_y_p_z = transport_y_batched_channel(W_batch_i_x_y_z, links, 1)\n",
        "        # W_batch_i_x_y_m = transport_y_batched_channel(W_batch_i_x_y, links, -1)\n",
        "        W_batch_i_x_y_z_p = transport_z_batched_channel(W_batch_i_x_y_z, links, 1)\n",
        "\n",
        "        # combine the transported terms into a single object and then include the sum over k (the convolution)\n",
        "        # by folding it into the channel label\n",
        "        W_trans_batch_i_x_y_z = jnp.concatenate([W_batch_i_x_y_z, W_batch_i_x_p_y_z, W_batch_i_x_y_p_z, W_batch_i_x_y_z_p], axis=1)\n",
        "\n",
        "        # include unit matrix at this point\n",
        "        # without the unit matrix, you discard the smaller Wilson loops!\n",
        "        batch_size = W_batch_i_x_y_z.shape[0]\n",
        "        dim_x = W_batch_i_x_y_z.shape[2]\n",
        "        dim_y = W_batch_i_x_y_z.shape[3]\n",
        "        dim_z = W_batch_i_x_y_z.shape[4]\n",
        "        Id_batch_i_x_y_z = jnp.ones((batch_size,1,dim_x,dim_y,dim_z))\n",
        "\n",
        "        # add conjugate of W variables to both W and W_trans\n",
        "        # and the unit matrix\n",
        "        # doubles the channels\n",
        "        W_batch_i_x_y_z = jnp.concatenate([W_batch_i_x_y_z, jnp.conj(W_batch_i_x_y_z),Id_batch_i_x_y_z], axis=1)\n",
        "        W_trans_batch_i_x_y_z = jnp.concatenate([W_trans_batch_i_x_y_z, jnp.conj(W_trans_batch_i_x_y_z), Id_batch_i_x_y_z], axis=1)\n",
        "\n",
        "        # number of channels in W and W_trans with conjugates included\n",
        "        W_channels = W_batch_i_x_y_z.shape[1]\n",
        "        W_trans_channels = W_trans_batch_i_x_y_z.shape[1]\n",
        "\n",
        "        alpha = self.param('alpha', nn.initializers.normal(), (self.N_out, W_channels, W_trans_channels), jnp.complex64)\n",
        "\n",
        "        out = jnp.einsum('ijk, bjxyz, bkxyz -> bixyz', alpha, W_batch_i_x_y_z, W_trans_batch_i_x_y_z, optimize='optimal')\n",
        "\n",
        "        # return the output\n",
        "        return out\n",
        "\n",
        "# Create an instance of the model.\n",
        "model_3 = LConvBilin(N_out=7)\n",
        "\n",
        "\n",
        "x = hi.random_state(key=jax.random.PRNGKey(0), size=100)\n",
        "\n",
        "links = model_1.apply(params_1, x)\n",
        "\n",
        "plaqs = model_2.apply(params_2, links)\n",
        "\n",
        "print(x.shape)\n",
        "\n",
        "key1, key2 = random.split(random.PRNGKey(0))\n",
        "params_3 = model_3.init(key1, links, plaqs) # Initialization call\n",
        "#jax.tree_util.tree_map(lambda x: x.shape, params) # Checking output shapes\n",
        "\n",
        "from jax import random\n",
        "\n",
        "# a1 = jax.random.uniform(key1, shape=(3, 2, 10))\n",
        "# a2 = jax.random.uniform(key1, shape=(6,2,3,3))\n",
        "# a3 = jax.random.uniform(key1, shape=(6,10,3,3))\n",
        "\n",
        "# path_info = jnp.einsum_path('ijk, bjxy, bkxy -> bixy', a1, a2, a3, optimize='optimal')\n",
        "# print(path_info)\n",
        "\n",
        "print(x)\n",
        "print(model_3.apply(params_3, links, plaqs).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYDc6QVV46CH",
        "outputId": "43243d13-0a65-4c32-f8ec-635f210ba33a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 375)\n",
            "[[ 0.  0.  2. ... -2.  2. -2.]\n",
            " [ 2. -2.  2. ...  2.  0.  0.]\n",
            " [-2. -2.  2. ...  2. -2.  2.]\n",
            " ...\n",
            " [ 0.  0. -2. ...  2.  0.  2.]\n",
            " [ 0.  2.  0. ... -2.  2. -2.]\n",
            " [-2.  0. -2. ...  2.  0.  2.]]\n",
            "(100, 7, 5, 5, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Flax model that uses the LConvBilin layers followed by a dense layer and relu"
      ],
      "metadata": {
        "id": "ZlHJvoeV5J1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A Flax model must be a class subclassing `nn.Module`\n",
        "# The most compact way to define the model is this.\n",
        "# The __call__(self, x) function should take as\n",
        "# input a batch of states shape = (n_batch, spin_states_vector)\n",
        "# and should return (n_batch, 0 or 1, x coord, y coord)\n",
        "# where the coords refer to the node to which the links are associated\n",
        "class MultiLConvBilin(nn.Module):\n",
        "\n",
        "    # You can define attributes at the module-level\n",
        "    # with a default. This allows you to easily change\n",
        "    # some hyper-parameter without redefining the whole\n",
        "    # flax module.\n",
        "    # corresponds to N of Z_N\n",
        "    N: int\n",
        "    N_out: Sequence[int]\n",
        "    features: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "\n",
        "        links = ZN_to_Phase(self.N)(x)\n",
        "        W_i_x_y_z = Plaq()(links)\n",
        "\n",
        "        for i in range(len(self.N_out)):\n",
        "            W_i_x_y_z = LConvBilin(self.N_out[i])(links, W_i_x_y_z)\n",
        "\n",
        "        W_i_x_y_z_flat = W_i_x_y_z.reshape(W_i_x_y_z.shape[0], -1)\n",
        "\n",
        "        # dense = nn.Dense(features=self.features * W_i_x_y_flat.shape[-1], kernel_init=nn.initializers.normal(), param_dtype=jnp.complex64)\n",
        "        dense = nn.Dense(features=self.features, kernel_init=nn.initializers.normal(), param_dtype=jnp.complex64)\n",
        "\n",
        "        # we apply the dense layer to the input\n",
        "        y = dense(W_i_x_y_z_flat)\n",
        "\n",
        "        # the non-linearity is a simple ReLu\n",
        "        y = nn.relu(y)\n",
        "\n",
        "        # return the output\n",
        "        return jnp.sum(y, axis=-1)\n",
        "\n",
        "# Create an instance of the model.\n",
        "model_5 = MultiLConvBilin(N=2, N_out=(4,5), features=10)\n",
        "\n",
        "# Create the local sampler on the hilbert space\n",
        "#sampler = nk.sampler.MetropolisLocal(hi)\n",
        "\n",
        "# Construct the variational state using the model and the sampler above.\n",
        "# n_samples specifies how many samples should be used to compute expectation\n",
        "# values.\n",
        "#vstate = nk.vqs.MCState(sampler, model, n_samples=1000)\n",
        "\n",
        "#vstate.n_parameters\n",
        "\n",
        "x = hi.random_state(key=jax.random.PRNGKey(0), size=7)\n",
        "\n",
        "key1, key2 = random.split(random.PRNGKey(0))\n",
        "params_5 = model_5.init(key1, x) # Initialization call\n",
        "print(jax.tree_util.tree_map(lambda x: x.shape, params_5)) # Checking output shapes\n",
        "\n",
        "print(model_5.apply(params_5, x))\n",
        "\n",
        "%timeit model_5.apply(params_5, x)\n",
        "# very slow!\n",
        "# %timeit jax.jit(model_5.apply)(params_5, x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTEWLJWzdtIk",
        "outputId": "0055d8a4-0462-478d-b9e0-55c56d1957eb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FrozenDict({\n",
            "    params: {\n",
            "        Dense_0: {\n",
            "            bias: (10,),\n",
            "            kernel: (625, 10),\n",
            "        },\n",
            "        LConvBilin_0: {\n",
            "            alpha: (4, 7, 25),\n",
            "        },\n",
            "        LConvBilin_1: {\n",
            "            alpha: (5, 9, 33),\n",
            "        },\n",
            "    },\n",
            "})\n",
            "[0.00562566+0.00944807j 0.01203134+0.00626987j 0.01416953+0.00649528j\n",
            " 0.00499984+0.00129483j 0.00972045+0.00102862j 0.01080763-0.00423907j\n",
            " 0.01515411+0.00099925j]\n",
            "19.5 ms ± 2.29 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use new layers to compute ground state"
      ],
      "metadata": {
        "id": "9sv8AqLW5Qt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model.\n",
        "# N is the N of Z_N\n",
        "# N_out is a tuple giving the number of output channels for each LConvBilin layer\n",
        "# longer tuples generate larger Wilson loops\n",
        "# features is the number of nodes in the dense layer\n",
        "model = MultiLConvBilin(N=ZN, N_out=(1,), features=50)\n",
        "\n",
        "# Create the local sampler on the hilbert space\n",
        "# https://github.com/orgs/netket/discussions/1384 suggests you should use a large number of chains on a gpu\n",
        "# the default is 16\n",
        "# https://github.com/orgs/netket/discussions/694 also suggests that you need a large number of samples per chain\n",
        "# TODO: understand interplay between these\n",
        "sampler = nk.sampler.MetropolisLocal(hi, n_chains=64)\n",
        "\n",
        "# Construct the variational state using the model and the sampler above.\n",
        "# n_samples specifies how many samples should be used to compute expectation\n",
        "# values.\n",
        "\n",
        "# Specify chunk_size in the variational state in order to reduce memory consumption. As we have L^3 sites,\n",
        "# at every VMC step we will need to evaluate the network for O(N_samples x L^3) different configurations,\n",
        "# but the memory available on commercial GPUs will not be enough to perform this computation in a single pass. Instead, by\n",
        "# setting chunk_size NetKet will split the calculation in many smaller sub-calculations\n",
        "vstate = nk.vqs.MCState(sampler, model, n_samples=1024, chunk_size=1024)\n",
        "\n",
        "vstate.init_parameters(nn.initializers.normal(stddev=0.01))\n",
        "\n",
        "# print(vstate.parameters)\n",
        "print(vstate.n_parameters)\n",
        "\n",
        "x = hi.random_state(key=jax.random.PRNGKey(0), size=3)\n",
        "\n",
        "\n",
        "key1, key2 = random.split(random.PRNGKey(0))\n",
        "params = model.init(key2, x) # Initialization call\n",
        "jax.tree_util.tree_map(lambda x: x.shape, params) # Checking output shapes\n",
        "\n",
        "model.apply(params, x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urqbU19li0uX",
        "outputId": "26842a47-2263-4bc1-e92e-a4d450e1807f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6475\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([0.27123877-0.05175004j, 0.16409596+0.03998997j,\n",
              "       0.13817863+0.01963724j], dtype=complex128)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Then we create an optimiser from the standard library.\n",
        "# You can also use optax.\n",
        "optimizer = nk.optimizer.Sgd(learning_rate=0.01)\n",
        "\n",
        "# build the optimisation driver\n",
        "# Notice the use of Stochastic Reconfiguration which considerably improves the optimisation\n",
        "gs = nk.driver.VMC(H, optimizer, variational_state=vstate, preconditioner=nk.optimizer.SR(diag_shift=0.01))\n",
        "\n",
        "log = nk.logging.RuntimeLog()\n",
        "\n",
        "gs.run(n_iter=300, out=log)\n",
        "\n",
        "ffn_energy = vstate.expect(H)\n",
        "\n",
        "# error = abs((ffn_energy.mean - E_gs)/E_gs)\n",
        "\n",
        "# print(\"Optimised energy and relative error:\", ffn_energy,error)\n",
        "\n",
        "nn_energy = vstate.expect(H).mean\n",
        "# nn_energy_penalty = vstate.expect(H_penalty).mean\n",
        "# nn_gauge = vstate.expect(gauge).mean\n",
        "\n",
        "\n",
        "# print(\"Optimised energy per site (with gauge penalty):\", (nn_energy_penalty + 10. * nx * nx)/ (nx * ny))\n",
        "# print(\"Expectation of gauge operator:\", nn_gauge)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "TJGwsAC9jBcK",
        "outputId": "c5dedc30-219b-4c7c-c6c8-6a6b88a230e7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▋         | 19/300 [12:44<3:08:26, 40.24s/it, Energy=126.3+0.4j ± 2.0 [σ²=3912.9, R̂=1.0213]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-8632bad9a385>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRuntimeLog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mffn_energy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/netket/driver/abstract_variational_driver.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, n_iter, out, obs, show_progress, save_params_every, write_every, step_size, callback)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mfirst_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlog_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/netket/driver/abstract_variational_driver.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, n_steps, step)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0mdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_and_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/netket/driver/vmc.py\u001b[0m in \u001b[0;36m_forward_and_backward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;31m# Compute the local energy estimator and average Energy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ham\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# if it's the identity it does\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/netket/vqs/mc/mc_state/state.py\u001b[0m in \u001b[0;36mexpect_and_grad\u001b[0;34m(self, Ô, mutable, use_covariance)\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0mmutable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         return expect_and_grad(\n\u001b[0m\u001b[1;32m    596\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m\u001b[0;31m̂\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_covariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmutable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/plum/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kw_args)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/netket/vqs/base.py\u001b[0m in \u001b[0;36mexpect_and_grad\u001b[0;34m(vstate, operator, use_covariance, mutable, *args, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0muse_covariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrueT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_hermitian\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mFalseT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m     return expect_and_grad(\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0mvstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_covariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmutable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/plum/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kw_args)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/plum/function.py\u001b[0m in \u001b[0;36mf_renamed\u001b[0;34m(*args, **kw_args)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mf_renamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mf_renamed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/netket/vqs/mc/mc_state/expect_grad_chunked.py\u001b[0m in \u001b[0;36mexpect_and_grad_covariance_chunked\u001b[0;34m(vstate, Ô, use_covariance, chunk_size, mutable)\u001b[0m\n\u001b[1;32m     73\u001b[0m ) -> Tuple[Stats, PyTree]:\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mO\u001b[0m\u001b[0;31m̄\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m\u001b[0;31m̄\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpect_and_forces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m\u001b[0;31m̂\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmutable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mO\u001b[0m\u001b[0;31m̄\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_force_to_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;31m̄\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mO\u001b[0m\u001b[0;31m̄\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m\u001b[0;31m̄\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/plum/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kw_args)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/plum/function.py\u001b[0m in \u001b[0;36mf_renamed\u001b[0;34m(*args, **kw_args)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mf_renamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mf_renamed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/netket/vqs/mc/mc_state/expect_forces_chunked.py\u001b[0m in \u001b[0;36mexpect_and_forces_impl\u001b[0;34m(vstate, Ô, chunk_size, mutable)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mmutable\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCollectionFilter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m ) -> Tuple[Stats, PyTree]:\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mσ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_local_kernel_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m\u001b[0;31m̂\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mlocal_estimator_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_local_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m\u001b[0;31m̂\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/plum/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kw_args)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/netket/vqs/mc/mc_state/expect.py\u001b[0m in \u001b[0;36mget_local_kernel_arguments\u001b[0;34m(vstate, Ô)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mcheck_hilbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhilbert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m\u001b[0;31m̂\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhilbert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mσ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mσp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mO\u001b[0m\u001b[0;31m̂\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_conn_padded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mσ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mσ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mσp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/netket/vqs/mc/mc_state/state.py\u001b[0m in \u001b[0;36msamples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \"\"\"\n\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/netket/vqs/mc/mc_state/state.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, chain_length, n_samples, n_discard_per_chain)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_discard_per_chain\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m             _, self.sampler_state = self.sampler.sample(\n\u001b[0m\u001b[1;32m    482\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/netket/sampler/base.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(sampler, machine, parameters, state, chain_length)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmachine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         return sampler._sample_chain(\n\u001b[0m\u001b[1;32m    275\u001b[0m             \u001b[0mwrap_afun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmachine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/netket/utils/struct/dataclass.py\u001b[0m in \u001b[0;36mclz_from_iterable\u001b[0;34m(meta, data)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mclz_from_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0mmeta_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_fields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mdata_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare energies with Figure 6 of 2008.00882.\n",
        "e.g. for $\\mathbb{Z}_3$ and $g=2$, approx $0.245$ energy per site."
      ],
      "metadata": {
        "id": "IbLxT2ak859h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Optimised energy:\", nn_energy)\n",
        "print(\"Optimised energy per site:\", nn_energy / (nx * ny * nz))\n",
        "print(\"Gauge invariance condition: \", vstate.expect(gauge_zero).mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrRPFhRRtAJG",
        "outputId": "fdfa7f1e-538a-4741-fe25-a2dfeea47ddc"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimised energy: (20.143976038667947+1.0179008036422983e-05j)\n",
            "Optimised energy per site: (0.3147496256041867+1.590470005691091e-07j)\n",
            "Gauge invariance condition:  1.2234543890141114e-17j\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Network built just from the 1x1 Wilson loops and their conjugates"
      ],
      "metadata": {
        "id": "qCtEzRigNdhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A Flax model must be a class subclassing `nn.Module`\n",
        "# The most compact way to define the model is this.\n",
        "# The __call__(self, x) function should take as\n",
        "# input a batch of states shape = (n_batch, spin_states_vector)\n",
        "# and should return (n_batch, 0 or 1, x coord, y coord)\n",
        "# where the coords refer to the node to which the links are associated\n",
        "class WilsonLoops(nn.Module):\n",
        "\n",
        "    # You can define attributes at the module-level\n",
        "    # with a default. This allows you to easily change\n",
        "    # some hyper-parameter without redefining the whole\n",
        "    # flax module.\n",
        "    # corresponds to N of Z_N\n",
        "    N: int\n",
        "    features: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "\n",
        "        links = ZN_to_Phase(self.N)(x)\n",
        "        W_i_x_y = Plaq()(links)\n",
        "\n",
        "        W_i_x_y = jnp.concatenate([W_i_x_y, jnp.conj(W_i_x_y)], axis=1)\n",
        "\n",
        "        W_i_x_y_flat = W_i_x_y.reshape(W_i_x_y.shape[0], -1)\n",
        "\n",
        "        # dense = nn.Dense(features=self.features * W_i_x_y_flat.shape[-1], kernel_init=nn.initializers.normal(), param_dtype=jnp.complex64)\n",
        "        dense = nn.Dense(features=self.features, kernel_init=nn.initializers.normal(), param_dtype=jnp.complex64)\n",
        "\n",
        "        # we apply the dense layer to the input\n",
        "        y = dense(W_i_x_y_flat)\n",
        "\n",
        "        # the non-linearity is a simple ReLu\n",
        "        y = nn.relu(y)\n",
        "\n",
        "        # return the output\n",
        "        return jnp.sum(y, axis=-1)"
      ],
      "metadata": {
        "id": "EfSV3AJ_MsU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model.\n",
        "model = WilsonLoops(N=ZN, features=1)\n",
        "\n",
        "# Create the local sampler on the hilbert space\n",
        "sampler = nk.sampler.MetropolisLocal(hi)\n",
        "\n",
        "# Construct the variational state using the model and the sampler above.\n",
        "# n_samples specifies how many samples should be used to compute expectation\n",
        "# values.\n",
        "vstate = nk.vqs.MCState(sampler, model, n_samples=1000)\n",
        "\n",
        "vstate.init_parameters(nn.initializers.normal(stddev=0.01))\n",
        "\n",
        "# print(vstate.parameters)\n",
        "print(vstate.n_parameters)\n",
        "\n",
        "x = hi.random_state(key=jax.random.PRNGKey(0), size=3)\n",
        "\n",
        "\n",
        "key1, key2 = random.split(random.PRNGKey(0))\n",
        "params = model.init(key2, x) # Initialization call\n",
        "jax.tree_util.tree_map(lambda x: x.shape, params) # Checking output shapes\n",
        "\n",
        "model.apply(params, x)"
      ],
      "metadata": {
        "id": "yw_eRiIFNKB3",
        "outputId": "63a87f2c-4664-4f89-8e19-b951801fae4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "342\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([0.10019006+0.00613986j, 0.1455523 +0.02302506j,\n",
              "       0.2440516 +0.08090451j], dtype=complex64)"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Then we create an optimiser from the standard library.\n",
        "# You can also use optax.\n",
        "optimizer = nk.optimizer.Sgd(learning_rate=0.05)\n",
        "\n",
        "# build the optimisation driver\n",
        "# Notice the use of Stochastic Reconfiguration which considerably improves the optimisation\n",
        "gs = nk.driver.VMC(H, optimizer, variational_state=vstate, preconditioner=nk.optimizer.SR(diag_shift=0.05))\n",
        "\n",
        "log = nk.logging.RuntimeLog()\n",
        "\n",
        "gs.run(n_iter=300, out=log)\n",
        "\n",
        "ffn_energy = vstate.expect(H)\n",
        "\n",
        "error = abs((ffn_energy.mean - E_gs)/E_gs)\n",
        "\n",
        "print(\"Optimised energy and relative error:\", ffn_energy,error)"
      ],
      "metadata": {
        "id": "IHqoQiwVNNOg",
        "outputId": "f6838470-0ba8-45a9-a982-8f84ef40dae4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:40<00:00,  7.47it/s, Energy=-9.2066+0.0001j ± 0.0043 [σ²=0.0183, R̂=1.0139]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimised energy and relative error: -9.2100-0.0000j ± 0.0028 [σ²=0.0081, R̂=0.9952] 5.1521952776696085e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_FFN = log.data\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.errorbar(data_FFN[\"Energy\"].iters, data_FFN[\"Energy\"].Mean, yerr=data_FFN[\"Energy\"].Sigma, label=\"FFN\")\n",
        "plt.hlines([E_gs], xmin=0, xmax=300, color='black', label=\"Exact\")\n",
        "plt.legend()\n",
        "\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Energy')"
      ],
      "metadata": {
        "id": "-YnbPM6eNQwv",
        "outputId": "e11596c5-e423-4559-d4b9-9086ba4a77ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Energy')"
            ]
          },
          "metadata": {},
          "execution_count": 137
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1vZL_cm_oKvT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPKmY/W3Gp4jeqJDkFbuihs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}